<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>61f90dba68d14c488bbea133b4199e80</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="predict-bike-sharing-demand-with-autogluon-template"
class="cell markdown">
<h1>Predict Bike Sharing Demand with AutoGluon Template</h1>
</section>
<section id="project-predict-bike-sharing-demand-with-autogluon"
class="cell markdown">
<h2>Project: Predict Bike Sharing Demand with AutoGluon</h2>
<p>This notebook is a template with each step that you need to complete
for the project.</p>
<p>Please fill in your code where there are explicit <code>?</code>
markers in the notebook. You are welcome to add more cells and code as
you see fit.</p>
<p>Once you have completed all the code implementations, please export
your notebook as a HTML file so the reviews can view your code. Make
sure you have all outputs correctly outputted.</p>
<p><code>File-&gt; Export Notebook As... -&gt; Export Notebook as HTML</code></p>
<p>There is a writeup to complete as well after all code implememtation
is done. Please answer all questions and attach the necessary tables and
charts. You can complete the writeup in either markdown or PDF.</p>
<p>Completing the code template and writeup template will cover all of
the rubric points for this project.</p>
<p>The rubric contains "Stand Out Suggestions" for enhancing the project
beyond the minimum requirements. The stand out suggestions are optional.
If you decide to pursue the "stand out suggestions", you can include the
code in this notebook and also discuss the results in the writeup
file.</p>
</section>
<section id="step-1-create-an-account-with-kaggle"
class="cell markdown">
<h2>Step 1: Create an account with Kaggle</h2>
</section>
<section id="create-kaggle-account-and-download-api-key"
class="cell markdown">
<h3>Create Kaggle Account and download API key</h3>
<p>Below is example of steps to get the API username and key. Each
student will have their own username and key.</p>
</section>
<div class="cell markdown">
<ol>
<li>Open account settings. <img
src="vertopal_5a3329f1f7c34305ae70eb667a8aba9d/kaggle1.png"
alt="kaggle1.png" /> <img
src="vertopal_5a3329f1f7c34305ae70eb667a8aba9d/kaggle2.png"
alt="kaggle2.png" /></li>
<li>Scroll down to API and click Create New API Token. <img
src="vertopal_5a3329f1f7c34305ae70eb667a8aba9d/kaggle3.png"
alt="kaggle3.png" /> <img
src="vertopal_5a3329f1f7c34305ae70eb667a8aba9d/kaggle4.png"
alt="kaggle4.png" /></li>
<li>Open up <code>kaggle.json</code> and use the username and key. <img
src="vertopal_5a3329f1f7c34305ae70eb667a8aba9d/kaggle5.png"
alt="kaggle5.png" /></li>
</ol>
</div>
<section
id="step-2-download-the-kaggle-dataset-using-the-kaggle-python-library"
class="cell markdown">
<h2>Step 2: Download the Kaggle dataset using the kaggle python
library</h2>
</section>
<section id="open-up-sagemaker-studio-and-use-starter-template"
class="cell markdown">
<h3>Open up Sagemaker Studio and use starter template</h3>
</section>
<div class="cell markdown">
<ol>
<li>Notebook should be using a <code>ml.t3.medium</code> instance (2
vCPU + 4 GiB)</li>
<li>Notebook should be using kernal:
<code>Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)</code></li>
</ol>
</div>
<section id="install-packages" class="cell markdown">
<h3>Install packages</h3>
</section>
<div class="cell code" data-execution_count="2"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T18:51:26.072381Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T18:51:26.071983Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T18:55:12.280795Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T18:55:12.279416Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T18:51:26.072344Z&quot;}"
data-tags="[]" data-trusted="true">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U pip</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U setuptools wheel</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U <span class="st">&quot;mxnet&lt;2.0.0&quot;</span> bokeh<span class="op">==</span><span class="fl">2.0.1</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install autogluon <span class="op">--</span>no<span class="op">-</span>cache<span class="op">-</span><span class="bu">dir</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install kaggle</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Without --no-cache-dir, smaller aws instances may have trouble installing</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.1.2)
WARNING: Running pip as the &#39;root&#39; user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (59.8.0)
Collecting setuptools
  Downloading setuptools-67.8.0-py3-none-any.whl (1.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 14.0 MB/s eta 0:00:0000:010:01
ent already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (0.40.0)
Installing collected packages: setuptools
  Attempting uninstall: setuptools
    Found existing installation: setuptools 59.8.0
    Uninstalling setuptools-59.8.0:
      Successfully uninstalled setuptools-59.8.0
ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
momepy 0.6.0 requires shapely&gt;=2, but you have shapely 1.8.5.post1 which is incompatible.
opentelemetry-api 1.17.0 requires importlib-metadata~=6.0.0, but you have importlib-metadata 5.2.0 which is incompatible.
pymc3 3.11.5 requires numpy&lt;1.22.2,&gt;=1.15.0, but you have numpy 1.23.5 which is incompatible.
pymc3 3.11.5 requires scipy&lt;1.8.0,&gt;=1.7.3, but you have scipy 1.10.1 which is incompatible.
Successfully installed setuptools-67.8.0
WARNING: Running pip as the &#39;root&#39; user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
Collecting mxnet&lt;2.0.0
  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.1/49.1 MB 25.6 MB/s eta 0:00:0000:0100:01
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.6/8.6 MB 91.5 MB/s eta 0:00:00:00:0100:01
etadata (setup.py) ... ent already satisfied: PyYAML&gt;=3.10 in /opt/conda/lib/python3.10/site-packages (from bokeh==2.0.1) (5.4.1)
Requirement already satisfied: python-dateutil&gt;=2.1 in /opt/conda/lib/python3.10/site-packages (from bokeh==2.0.1) (2.8.2)
Requirement already satisfied: Jinja2&gt;=2.7 in /opt/conda/lib/python3.10/site-packages (from bokeh==2.0.1) (3.1.2)
Requirement already satisfied: numpy&gt;=1.11.3 in /opt/conda/lib/python3.10/site-packages (from bokeh==2.0.1) (1.23.5)
Requirement already satisfied: pillow&gt;=4.0 in /opt/conda/lib/python3.10/site-packages (from bokeh==2.0.1) (9.5.0)
Requirement already satisfied: packaging&gt;=16.8 in /opt/conda/lib/python3.10/site-packages (from bokeh==2.0.1) (21.3)
Requirement already satisfied: tornado&gt;=5 in /opt/conda/lib/python3.10/site-packages (from bokeh==2.0.1) (6.3.1)
Requirement already satisfied: typing_extensions&gt;=3.7.4 in /opt/conda/lib/python3.10/site-packages (from bokeh==2.0.1) (4.5.0)
Requirement already satisfied: requests&lt;3,&gt;=2.20.0 in /opt/conda/lib/python3.10/site-packages (from mxnet&lt;2.0.0) (2.28.2)
Collecting graphviz&lt;0.9.0,&gt;=0.8.1 (from mxnet&lt;2.0.0)
  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2&gt;=2.7-&gt;bokeh==2.0.1) (2.1.2)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging&gt;=16.8-&gt;bokeh==2.0.1) (3.0.9)
Requirement already satisfied: six&gt;=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil&gt;=2.1-&gt;bokeh==2.0.1) (1.16.0)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/conda/lib/python3.10/site-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (2.1.1)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/conda/lib/python3.10/site-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (3.4)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (1.26.15)
Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (2023.5.7)
Building wheels for collected packages: bokeh
  Building wheel for bokeh (setup.py) ... e=bokeh-2.0.1-py3-none-any.whl size=9080019 sha256=24aae8210270ab306779799b3f81b880ceac6a9894e903085099ddf08779b068
  Stored in directory: /root/.cache/pip/wheels/be/b4/d8/7ce778fd6e637bea03a561223a77ba6649aff8168e3c613754
Successfully built bokeh
Installing collected packages: graphviz, mxnet, bokeh
  Attempting uninstall: graphviz
    Found existing installation: graphviz 0.20.1
    Uninstalling graphviz-0.20.1:
      Successfully uninstalled graphviz-0.20.1
  Attempting uninstall: bokeh
    Found existing installation: bokeh 2.4.3
    Uninstalling bokeh-2.4.3:
      Successfully uninstalled bokeh-2.4.3
ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
geoviews 1.9.6 requires bokeh&lt;2.5,&gt;=2.4.0, but you have bokeh 2.0.1 which is incompatible.
panel 0.14.4 requires bokeh&lt;2.5.0,&gt;=2.4.0, but you have bokeh 2.0.1 which is incompatible.
Successfully installed bokeh-2.0.1 graphviz-0.8.4 mxnet-1.9.1
WARNING: Running pip as the &#39;root&#39; user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
Collecting autogluon
  Downloading autogluon-0.7.0-py3-none-any.whl (9.7 kB)
Collecting autogluon.core[all]==0.7.0 (from autogluon)
  Downloading autogluon.core-0.7.0-py3-none-any.whl (218 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 218.3/218.3 kB 6.7 MB/s eta 0:00:00
 autogluon)
  Downloading autogluon.features-0.7.0-py3-none-any.whl (60 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.1/60.1 kB 193.7 MB/s eta 0:00:00
 autogluon)
  Downloading autogluon.tabular-0.7.0-py3-none-any.whl (292 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 292.2/292.2 kB 30.4 MB/s eta 0:00:00
ultimodal==0.7.0 (from autogluon)
  Downloading autogluon.multimodal-0.7.0-py3-none-any.whl (331 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 331.1/331.1 kB 256.4 MB/s eta 0:00:00
eseries[all]==0.7.0 (from autogluon)
  Downloading autogluon.timeseries-0.7.0-py3-none-any.whl (108 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 108.7/108.7 kB 137.6 MB/s eta 0:00:00
ent already satisfied: numpy&lt;1.27,&gt;=1.21 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.23.5)
Requirement already satisfied: scipy&lt;1.12,&gt;=1.5.4 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.10.1)
Requirement already satisfied: scikit-learn&lt;1.3,&gt;=1.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.2.2)
Collecting networkx&lt;3.0,&gt;=2.3 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 120.7 MB/s eta 0:00:00
ent already satisfied: pandas&lt;1.6,&gt;=1.4.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.5.3)
Requirement already satisfied: tqdm&lt;5,&gt;=4.38 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (4.64.1)
Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (2.28.2)
Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (3.6.3)
Requirement already satisfied: boto3&lt;2,&gt;=1.10 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.26.100)
Collecting autogluon.common==0.7.0 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading autogluon.common-0.7.0-py3-none-any.whl (45 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.0/45.0 kB 171.6 MB/s eta 0:00:00
ent already satisfied: hyperopt&lt;0.2.8,&gt;=0.2.7 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (0.2.7)
Collecting ray[tune]&lt;2.3,&gt;=2.2 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading ray-2.2.0-cp310-cp310-manylinux2014_x86_64.whl (57.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.4/57.4 MB 190.8 MB/s eta 0:00:00a 0:00:01
ent already satisfied: Pillow&lt;9.6,&gt;=9.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (9.5.0)
Requirement already satisfied: jsonschema&lt;4.18,&gt;=4.14 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (4.17.3)
Collecting seqeval&lt;1.3.0,&gt;=1.2.2 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading seqeval-1.2.2.tar.gz (43 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 181.4 MB/s eta 0:00:00
etadata (setup.py) ...  autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.9/72.9 kB 222.4 MB/s eta 0:00:00
ent already satisfied: accelerate&lt;0.17,&gt;=0.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.12.0)
Collecting timm&lt;0.7.0,&gt;=0.6.12 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading timm-0.6.13-py3-none-any.whl (549 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 549.1/549.1 kB 259.5 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 887.5/887.5 MB 210.4 MB/s eta 0:00:0000:0100:01
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.2/24.2 MB 110.3 MB/s eta 0:00:00a 0:00:01
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading fairscale-0.4.13.tar.gz (266 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 266.3/266.3 kB 271.6 MB/s eta 0:00:00
ents to build wheel ... etadata (pyproject.toml) ... age&lt;0.20.0,&gt;=0.19.1 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading scikit_image-0.19.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.9 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.9/13.9 MB 163.2 MB/s eta 0:00:00a 0:00:01
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 829.5/829.5 kB 227.7 MB/s eta 0:00:00
ent already satisfied: text-unidecode&lt;1.4,&gt;=1.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (1.3)
Collecting torchmetrics&lt;0.9.0,&gt;=0.8.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 409.8/409.8 kB 286.5 MB/s eta 0:00:00
ers&lt;4.27.0,&gt;=4.23.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 141.4 MB/s eta 0:00:00a 0:00:01
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nptyping-2.4.1-py3-none-any.whl (36 kB)
Collecting omegaconf&lt;2.3.0,&gt;=2.1.1 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.3/79.3 kB 222.7 MB/s eta 0:00:00
ent already satisfied: sentencepiece&lt;0.2.0,&gt;=0.1.95 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.1.99)
Collecting pytorch-metric-learning&lt;2.0,&gt;=1.3.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pytorch_metric_learning-1.7.3-py3-none-any.whl (112 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 112.2/112.2 kB 237.5 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.5/410.5 kB 272.4 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 284.3 MB/s eta 0:00:00
im&lt;0.4.0,&gt;0.1.5 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading openmim-0.3.7-py2.py3-none-any.whl (51 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 51.3/51.3 kB 175.1 MB/s eta 0:00:00
ent already satisfied: defusedxml&lt;0.7.2,&gt;=0.7.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.7.1)
Requirement already satisfied: jinja2&lt;3.2,&gt;=3.0.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (3.1.2)
Requirement already satisfied: tensorboard&lt;3,&gt;=2.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (2.12.3)
Requirement already satisfied: pytesseract&lt;0.3.11,&gt;=0.3.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.3.10)
Collecting catboost&lt;1.2,&gt;=1.0 (from autogluon.tabular[all]==0.7.0-&gt;autogluon)
  Downloading catboost-1.1.1-cp310-none-manylinux1_x86_64.whl (76.6 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.6/76.6 MB 192.6 MB/s eta 0:00:0000:0100:01
ent already satisfied: lightgbm&lt;3.4,&gt;=3.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.3.2)
Requirement already satisfied: xgboost&lt;1.8,&gt;=1.6 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.7.5)
Requirement already satisfied: fastai&lt;2.8,&gt;=2.3.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.7.12)
Requirement already satisfied: joblib&lt;2,&gt;=1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.2.0)
Requirement already satisfied: statsmodels&lt;0.14,&gt;=0.13.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.13.5)
Collecting gluonts&lt;0.13,&gt;=0.12.0 (from autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading gluonts-0.12.8-py3-none-any.whl (1.2 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 272.9 MB/s eta 0:00:00
 autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading statsforecast-1.4.0-py3-none-any.whl (91 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.0/92.0 kB 196.0 MB/s eta 0:00:00
ent already satisfied: ujson&lt;6,&gt;=5 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (5.7.0)
Collecting sktime&lt;0.16,&gt;=0.14 (from autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading sktime-0.15.1-py3-none-any.whl (16.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.0/16.0 MB 178.7 MB/s eta 0:00:00a 0:00:01
 autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading tbats-1.1.3-py3-none-any.whl (44 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.0/44.0 kB 172.6 MB/s eta 0:00:00
darima&lt;1.9,&gt;=1.8.2 (from autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading pmdarima-1.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 219.4 MB/s eta 0:00:00
ent already satisfied: psutil&lt;6,&gt;=5.7.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.common==0.7.0-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (5.9.3)
Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from autogluon.common==0.7.0-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (67.8.0)
Requirement already satisfied: packaging&gt;=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate&lt;0.17,&gt;=0.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (21.3)
Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate&lt;0.17,&gt;=0.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (5.4.1)
Collecting botocore&lt;1.30.0,&gt;=1.29.100 (from boto3&lt;2,&gt;=1.10-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading botocore-1.29.143-py3-none-any.whl (10.8 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.8/10.8 MB 212.3 MB/s eta 0:00:00a 0:00:01
ent already satisfied: jmespath&lt;2.0.0,&gt;=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3&lt;2,&gt;=1.10-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.0.1)
Requirement already satisfied: s3transfer&lt;0.7.0,&gt;=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3&lt;2,&gt;=1.10-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.6.1)
Requirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.8.4)
Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (5.14.1)
Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.16.0)
Requirement already satisfied: datasets&gt;=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.1.0)
Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.3.6)
Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (3.2.0)
Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.70.14)
Requirement already satisfied: fsspec[http]&gt;=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2023.5.0)
Requirement already satisfied: huggingface-hub&gt;=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.14.1)
Requirement already satisfied: responses&lt;0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.18.0)
Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (23.1.2)
Requirement already satisfied: fastdownload&lt;2,&gt;=0.0.5 in /opt/conda/lib/python3.10/site-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.0.7)
Requirement already satisfied: fastcore&lt;1.6,&gt;=1.5.29 in /opt/conda/lib/python3.10/site-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.5.29)
Requirement already satisfied: fastprogress&gt;=0.2.4 in /opt/conda/lib/python3.10/site-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.0.3)
Requirement already satisfied: spacy&lt;4 in /opt/conda/lib/python3.10/site-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.5.3)
Requirement already satisfied: pydantic~=1.7 in /opt/conda/lib/python3.10/site-packages (from gluonts&lt;0.13,&gt;=0.12.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.10.7)
Requirement already satisfied: toolz~=0.10 in /opt/conda/lib/python3.10/site-packages (from gluonts&lt;0.13,&gt;=0.12.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.12.0)
Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gluonts&lt;0.13,&gt;=0.12.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (4.5.0)
Requirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from hyperopt&lt;0.2.8,&gt;=0.2.7-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.18.3)
Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from hyperopt&lt;0.2.8,&gt;=0.2.7-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.2.1)
Requirement already satisfied: py4j in /opt/conda/lib/python3.10/site-packages (from hyperopt&lt;0.2.8,&gt;=0.2.7-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.10.9.7)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2&lt;3.2,&gt;=3.0.3-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.1.2)
Requirement already satisfied: attrs&gt;=17.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema&lt;4.18,&gt;=4.14-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (23.1.0)
Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema&lt;4.18,&gt;=4.14-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.19.3)
Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from lightgbm&lt;3.4,&gt;=3.3-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.40.0)
Collecting gdown&gt;=4.0.0 (from nlpaug&lt;1.2.0,&gt;=1.1.10-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)
Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk&lt;4.0.0,&gt;=3.4.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (8.1.3)
Requirement already satisfied: regex&gt;=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk&lt;4.0.0,&gt;=3.4.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2023.5.5)
Collecting antlr4-python3-runtime==4.9.* (from omegaconf&lt;2.3.0,&gt;=2.1.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.0/117.0 kB 158.7 MB/s eta 0:00:00
etadata (setup.py) ... ent already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.4.6)
Collecting model-index (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)
Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (13.3.5)
Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.9.0)
Requirement already satisfied: python-dateutil&gt;=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas&lt;1.6,&gt;=1.4.1-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas&lt;1.6,&gt;=1.4.1-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2023.3)
Requirement already satisfied: Cython!=0.29.18,&gt;=0.29 in /opt/conda/lib/python3.10/site-packages (from pmdarima&lt;1.9,&gt;=1.8.2-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.29.34)
Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from pmdarima&lt;1.9,&gt;=1.8.2-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.26.15)
Requirement already satisfied: lightning-utilities&gt;=0.6.0.post0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning&lt;1.10.0,&gt;=1.9.0-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.8.0)
Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.12.0)
Requirement already satisfied: msgpack&lt;2.0.0,&gt;=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.0.5)
Requirement already satisfied: protobuf!=3.19.5,&gt;=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.20.3)
Requirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.3.1)
Requirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.3.3)
Requirement already satisfied: virtualenv&gt;=20.0.24 in /opt/conda/lib/python3.10/site-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (20.21.0)
Requirement already satisfied: grpcio&gt;=1.42.0 in /opt/conda/lib/python3.10/site-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.51.3)
Requirement already satisfied: tensorboardX&gt;=1.9 in /opt/conda/lib/python3.10/site-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.6)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.1.1)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2023.5.7)
Requirement already satisfied: imageio&gt;=2.4.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image&lt;0.20.0,&gt;=0.19.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.28.1)
Requirement already satisfied: tifffile&gt;=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image&lt;0.20.0,&gt;=0.19.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2023.4.12)
Requirement already satisfied: PyWavelets&gt;=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image&lt;0.20.0,&gt;=0.19.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.4.1)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn&lt;1.3,&gt;=1.0-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.1.0)
Requirement already satisfied: deprecated&gt;=1.2.13 in /opt/conda/lib/python3.10/site-packages (from sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.2.13)
Requirement already satisfied: numba&gt;=0.55 in /opt/conda/lib/python3.10/site-packages (from sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.57.0)
Requirement already satisfied: patsy&gt;=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels&lt;0.14,&gt;=0.13.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.5.3)
Requirement already satisfied: absl-py&gt;=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.4.0)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.17.3)
Requirement already satisfied: google-auth-oauthlib&lt;1.1,&gt;=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.0.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (3.4.3)
Requirement already satisfied: tensorboard-data-server&lt;0.8.0,&gt;=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.7.0)
Requirement already satisfied: werkzeug&gt;=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.3.4)
Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 849.3/849.3 kB 251.1 MB/s eta 0:00:00
 torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 557.1/557.1 MB 219.4 MB/s eta 0:00:0000:0100:01
 torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 317.1/317.1 MB 219.0 MB/s eta 0:00:0000:0100:01
 torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.0/21.0 MB 201.6 MB/s eta 0:00:00a 0:00:01
 torchmetrics&lt;0.9.0,&gt;=0.8.0-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)
Requirement already satisfied: tokenizers!=0.11.3,&lt;0.14,&gt;=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers&lt;4.27.0,&gt;=4.23.0-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.13.3)
Requirement already satisfied: contourpy&gt;=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.0.7)
Requirement already satisfied: cycler&gt;=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.11.0)
Requirement already satisfied: fonttools&gt;=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (4.39.3)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.4.4)
Requirement already satisfied: pyparsing&gt;=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.0.9)
Requirement already satisfied: pyarrow&gt;=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (9.0.0)
Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (3.8.4)
Requirement already satisfied: wrapt&lt;2,&gt;=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated&gt;=1.2.13-&gt;sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.14.1)
Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown&gt;=4.0.0-&gt;nlpaug&lt;1.2.0,&gt;=1.1.10-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.12.2)
Requirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.2.4)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.2.7)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.9)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib&lt;1.1,&gt;=0.5-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.3.1)
Requirement already satisfied: llvmlite&lt;0.41,&gt;=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba&gt;=0.55-&gt;sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.40.0)
Requirement already satisfied: spacy-legacy&lt;3.1.0,&gt;=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.0.12)
Requirement already satisfied: spacy-loggers&lt;2.0.0,&gt;=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.0.4)
Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.0.9)
Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.0.7)
Requirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.0.8)
Requirement already satisfied: thinc&lt;8.2.0,&gt;=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (8.1.10)
Requirement already satisfied: wasabi&lt;1.2.0,&gt;=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.1.1)
Requirement already satisfied: srsly&lt;3.0.0,&gt;=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.4.6)
Requirement already satisfied: catalogue&lt;2.1.0,&gt;=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.0.8)
Requirement already satisfied: typer&lt;0.8.0,&gt;=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.7.0)
Requirement already satisfied: pathy&gt;=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.10.1)
Requirement already satisfied: smart-open&lt;7.0.0,&gt;=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (6.3.0)
Requirement already satisfied: langcodes&lt;4.0.0,&gt;=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.3.0)
Requirement already satisfied: distlib&lt;1,&gt;=0.3.6 in /opt/conda/lib/python3.10/site-packages (from virtualenv&gt;=20.0.24-&gt;ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.3.6)
Requirement already satisfied: platformdirs&lt;4,&gt;=2.4 in /opt/conda/lib/python3.10/site-packages (from virtualenv&gt;=20.0.24-&gt;ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.5.0)
Collecting ordered-set (from model-index-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)
Requirement already satisfied: tenacity&gt;=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly-&gt;catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (8.2.2)
Requirement already satisfied: markdown-it-py&lt;3.0.0,&gt;=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.2.0)
Requirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.15.1)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (6.0.4)
Requirement already satisfied: async-timeout&lt;5.0,&gt;=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.0.2)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.9.1)
Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py&lt;3.0.0,&gt;=2.2.0-&gt;rich-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.1.2)
Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.4.8)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;1.1,&gt;=0.5-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (3.2.2)
Requirement already satisfied: blis&lt;0.8.0,&gt;=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc&lt;8.2.0,&gt;=8.1.8-&gt;spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.7.9)
Requirement already satisfied: confection&lt;1.0.0,&gt;=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc&lt;8.2.0,&gt;=8.1.8-&gt;spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.0.4)
Requirement already satisfied: soupsieve&gt;1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4-&gt;gdown&gt;=4.0.0-&gt;nlpaug&lt;1.2.0,&gt;=1.1.10-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.3.2.post1)
Requirement already satisfied: PySocks!=1.5.7,&gt;=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.7.1)
Building wheels for collected packages: fairscale, antlr4-python3-runtime, seqeval
  Building wheel for fairscale (pyproject.toml) ... e=fairscale-0.4.13-py3-none-any.whl size=332112 sha256=f4baef82e037f628da08ddbc3bba54e4132024b26da7c92151918205692b138a
  Stored in directory: /tmp/pip-ephem-wheel-cache-zmnjd06x/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3
  Building wheel for antlr4-python3-runtime (setup.py) ... e: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=ad21e60d5def617724e2e6d38321c0740cfe4a13bbffb71e9c525e79ec0a0f78
  Stored in directory: /tmp/pip-ephem-wheel-cache-zmnjd06x/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88
  Building wheel for seqeval (setup.py) ... e=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=59108f5f0c40cdd9706ddb93a045546341605a29bf57b2477ad879f2ccc36723
  Stored in directory: /tmp/pip-ephem-wheel-cache-zmnjd06x/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa
Successfully built fairscale antlr4-python3-runtime seqeval
Installing collected packages: antlr4-python3-runtime, pyDeprecate, ordered-set, omegaconf, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nptyping, nltk, networkx, scikit-image, ray, nvidia-cudnn-cu11, model-index, botocore, transformers, torch, seqeval, openmim, gluonts, gdown, catboost, torchvision, torchmetrics, statsforecast, sktime, pytorch-metric-learning, pmdarima, nlpaug, fairscale, timm, tbats, pytorch-lightning, evaluate, autogluon.common, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon
  Attempting uninstall: nltk
    Found existing installation: nltk 3.2.4
    Uninstalling nltk-3.2.4:
      Successfully uninstalled nltk-3.2.4
  Attempting uninstall: networkx
    Found existing installation: networkx 3.1
    Uninstalling networkx-3.1:
      Successfully uninstalled networkx-3.1
  Attempting uninstall: scikit-image
    Found existing installation: scikit-image 0.20.0
    Uninstalling scikit-image-0.20.0:
      Successfully uninstalled scikit-image-0.20.0
  Attempting uninstall: ray
    Found existing installation: ray 2.4.0
    Uninstalling ray-2.4.0:
      Successfully uninstalled ray-2.4.0
  Attempting uninstall: botocore
    Found existing installation: botocore 1.29.76
    Uninstalling botocore-1.29.76:
      Successfully uninstalled botocore-1.29.76
  Attempting uninstall: transformers
    Found existing installation: transformers 4.29.2
    Uninstalling transformers-4.29.2:
      Successfully uninstalled transformers-4.29.2
  Attempting uninstall: torch
    Found existing installation: torch 2.0.0+cpu
    Uninstalling torch-2.0.0+cpu:
      Successfully uninstalled torch-2.0.0+cpu
  Attempting uninstall: catboost
    Found existing installation: catboost 1.2
    Uninstalling catboost-1.2:
      Successfully uninstalled catboost-1.2
  Attempting uninstall: torchvision
    Found existing installation: torchvision 0.15.1+cpu
    Uninstalling torchvision-0.15.1+cpu:
      Successfully uninstalled torchvision-0.15.1+cpu
  Attempting uninstall: torchmetrics
    Found existing installation: torchmetrics 0.11.4
    Uninstalling torchmetrics-0.11.4:
      Successfully uninstalled torchmetrics-0.11.4
  Attempting uninstall: timm
    Found existing installation: timm 0.9.2
    Uninstalling timm-0.9.2:
      Successfully uninstalled timm-0.9.2
  Attempting uninstall: pytorch-lightning
    Found existing installation: pytorch-lightning 2.0.2
    Uninstalling pytorch-lightning-2.0.2:
      Successfully uninstalled pytorch-lightning-2.0.2
ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
aiobotocore 2.5.0 requires botocore&lt;1.29.77,&gt;=1.29.76, but you have botocore 1.29.143 which is incompatible.
momepy 0.6.0 requires shapely&gt;=2, but you have shapely 1.8.5.post1 which is incompatible.
preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.
torchaudio 2.0.1+cpu requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.
torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.
torchtext 0.15.1+cpu requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.
ydata-profiling 4.1.2 requires scipy&lt;1.10,&gt;=1.4.1, but you have scipy 1.10.1 which is incompatible.
Successfully installed antlr4-python3-runtime-4.9.3 autogluon-0.7.0 autogluon.common-0.7.0 autogluon.core-0.7.0 autogluon.features-0.7.0 autogluon.multimodal-0.7.0 autogluon.tabular-0.7.0 autogluon.timeseries-0.7.0 botocore-1.29.143 catboost-1.1.1 evaluate-0.3.0 fairscale-0.4.13 gdown-4.7.1 gluonts-0.12.8 model-index-0.1.11 networkx-2.8.8 nlpaug-1.1.11 nltk-3.8.1 nptyping-2.4.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 omegaconf-2.2.3 openmim-0.3.7 ordered-set-4.1.0 pmdarima-1.8.5 pyDeprecate-0.3.2 pytorch-lightning-1.9.5 pytorch-metric-learning-1.7.3 ray-2.2.0 scikit-image-0.19.3 seqeval-1.2.2 sktime-0.15.1 statsforecast-1.4.0 tbats-1.1.3 timm-0.6.13 torch-1.13.1 torchmetrics-0.8.2 torchvision-0.14.1 transformers-4.26.1
WARNING: Running pip as the &#39;root&#39; user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
Requirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (1.5.13)
Requirement already satisfied: six&gt;=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle) (1.16.0)
Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kaggle) (2023.5.7)
Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle) (2.8.2)
Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle) (2.28.2)
Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle) (4.64.1)
Requirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle) (8.0.1)
Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle) (1.26.15)
Requirement already satisfied: text-unidecode&gt;=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify-&gt;kaggle) (1.3)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;kaggle) (2.1.1)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;kaggle) (3.4)
WARNING: Running pip as the &#39;root&#39; user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
</code></pre>
</div>
</div>
<section id="setup-kaggle-api-key" class="cell markdown">
<h3>Setup Kaggle API Key</h3>
</section>
<div class="cell code" data-execution_count="3"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T18:55:12.283401Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T18:55:12.283037Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T18:55:15.288752Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T18:55:15.287146Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T18:55:12.283362Z&quot;}"
data-tags="[]" data-trusted="true">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create the .kaggle directory and an empty kaggle.json file</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>mkdir <span class="op">-</span>p <span class="op">/</span>root<span class="op">/</span>.kaggle</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>touch <span class="op">/</span>root<span class="op">/</span>.kaggle<span class="op">/</span>kaggle.json</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>chmod <span class="dv">600</span> <span class="op">/</span>root<span class="op">/</span>.kaggle<span class="op">/</span>kaggle.json</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="4"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T18:55:15.291076Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T18:55:15.290725Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T18:55:15.298867Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T18:55:15.297773Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T18:55:15.291036Z&quot;}"
data-tags="[]" data-trusted="true">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fill in your user name and key from creating the kaggle account and API token file</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>kaggle_username <span class="op">=</span> <span class="st">&quot;arthrow&quot;</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>kaggle_key <span class="op">=</span> <span class="st">&quot;76f062c6660cdae96218e31600c3cdaa&quot;</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Save API token the kaggle.json file</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">&quot;/root/.kaggle/kaggle.json&quot;</span>, <span class="st">&quot;w&quot;</span>) <span class="im">as</span> f:</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    f.write(json.dumps({<span class="st">&quot;username&quot;</span>: kaggle_username, <span class="st">&quot;key&quot;</span>: kaggle_key}))</span></code></pre></div>
</div>
<section id="download-and-explore-dataset" class="cell markdown">
<h3>Download and explore dataset</h3>
</section>
<section
id="go-to-the-bike-sharing-demand-competition-and-agree-to-the-terms"
class="cell markdown">
<h3>Go to the <a
href="https://www.kaggle.com/c/bike-sharing-demand">bike sharing demand
competition</a> and agree to the terms</h3>
<p><img src="vertopal_5a3329f1f7c34305ae70eb667a8aba9d/kaggle6.png"
alt="kaggle6.png" /></p>
</section>
<div class="cell code" data-execution_count="5"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T18:55:15.301989Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T18:55:15.301618Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T18:55:19.723078Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T18:55:19.721921Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T18:55:15.301954Z&quot;}"
data-tags="[]" data-trusted="true">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the dataset, it will be in a zip file so you&#39;ll need to unzip it as well.</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions download <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># If you already downloaded it you can use the -o command to overwrite the file</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>unzip <span class="op">-</span>o bike<span class="op">-</span>sharing<span class="op">-</span>demand.<span class="bu">zip</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Downloading bike-sharing-demand.zip to /kaggle/working
100%|█████████████████████████████████████████| 189k/189k [00:00&lt;00:00, 491kB/s]
100%|█████████████████████████████████████████| 189k/189k [00:00&lt;00:00, 491kB/s]
Archive:  bike-sharing-demand.zip
  inflating: sampleSubmission.csv    
  inflating: test.csv                
  inflating: train.csv               
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="6"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T18:55:19.725953Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T18:55:19.725620Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T18:55:20.700279Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T18:55:20.699370Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T18:55:19.725917Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> autogluon.tabular <span class="im">import</span> TabularPredictor</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="7"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T18:55:20.702051Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T18:55:20.701662Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T18:55:20.781947Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T18:55:20.780358Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T18:55:20.702015Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the train dataset in pandas by reading the csv</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the parsing of the datetime column so you can use some of the `dt` features in pandas later</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> train <span class="op">=</span> pd.read_csv(<span class="st">&quot;/kaggle/input/bike-sharing-demand/train.csv&quot;</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>train.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="7">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-01 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>81</td>
      <td>0.0</td>
      <td>3</td>
      <td>13</td>
      <td>16</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-01 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>8</td>
      <td>32</td>
      <td>40</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-01 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>5</td>
      <td>27</td>
      <td>32</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-01 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>3</td>
      <td>10</td>
      <td>13</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-01 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="8"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T18:55:20.784519Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T18:55:20.783856Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T18:55:20.846198Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T18:55:20.845386Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T18:55:20.784478Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>train.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="8">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.00000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2.506614</td>
      <td>0.028569</td>
      <td>0.680875</td>
      <td>1.418427</td>
      <td>20.23086</td>
      <td>23.655084</td>
      <td>61.886460</td>
      <td>12.799395</td>
      <td>36.021955</td>
      <td>155.552177</td>
      <td>191.574132</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.116174</td>
      <td>0.166599</td>
      <td>0.466159</td>
      <td>0.633839</td>
      <td>7.79159</td>
      <td>8.474601</td>
      <td>19.245033</td>
      <td>8.164537</td>
      <td>49.960477</td>
      <td>151.039033</td>
      <td>181.144454</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.82000</td>
      <td>0.760000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>13.94000</td>
      <td>16.665000</td>
      <td>47.000000</td>
      <td>7.001500</td>
      <td>4.000000</td>
      <td>36.000000</td>
      <td>42.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>3.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>20.50000</td>
      <td>24.240000</td>
      <td>62.000000</td>
      <td>12.998000</td>
      <td>17.000000</td>
      <td>118.000000</td>
      <td>145.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>4.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>26.24000</td>
      <td>31.060000</td>
      <td>77.000000</td>
      <td>16.997900</td>
      <td>49.000000</td>
      <td>222.000000</td>
      <td>284.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>4.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>4.000000</td>
      <td>41.00000</td>
      <td>45.455000</td>
      <td>100.000000</td>
      <td>56.996900</td>
      <td>367.000000</td>
      <td>886.000000</td>
      <td>977.000000</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="9"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T18:55:20.847786Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T18:55:20.847489Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T18:55:20.879283Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T18:55:20.878002Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T18:55:20.847760Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the test pandas dataframe in pandas by reading the csv, remember to parse the datetime!</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> pd.read_csv(<span class="st">&quot;/kaggle/input/bike-sharing-demand/test.csv&quot;</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>test.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="9">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-20 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>11.365</td>
      <td>56</td>
      <td>26.0027</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-20 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>13.635</td>
      <td>56</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-20 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>13.635</td>
      <td>56</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-20 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>12.880</td>
      <td>56</td>
      <td>11.0014</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-20 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>12.880</td>
      <td>56</td>
      <td>11.0014</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="10"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T18:55:20.880839Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T18:55:20.880424Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T18:55:20.901123Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T18:55:20.900175Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T18:55:20.880812Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same thing as train and test dataset</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>submission <span class="op">=</span> pd.read_csv(<span class="st">&quot;/kaggle/input/bike-sharing-demand/sampleSubmission.csv&quot;</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>submission.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="10">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-20 00:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-20 01:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-20 02:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-20 03:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-20 04:00:00</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<section id="step-3-train-a-model-using-autogluons-tabular-prediction"
class="cell markdown">
<h2>Step 3: Train a model using AutoGluon’s Tabular Prediction</h2>
</section>
<div class="cell markdown">
<p>Requirements:</p>
<ul>
<li>We are predicting <code>count</code>, so it is the label we are
setting.</li>
<li>Ignore <code>casual</code> and <code>registered</code> columns as
they are also not present in the test dataset.</li>
<li>Use the <code>root_mean_squared_error</code> as the metric to use
for evaluation.</li>
<li>Set a time limit of 10 minutes (600 seconds).</li>
<li>Use the preset <code>best_quality</code> to focus on creating the
best model.</li>
</ul>
</div>
<div class="cell code" data-execution_count="11"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T18:55:20.905685Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T18:55:20.905421Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:05:45.138191Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:05:45.137141Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T18:55:20.905662Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>predictor <span class="op">=</span> TabularPredictor(</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">&quot;count&quot;</span>,</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    problem_type<span class="op">=</span><span class="st">&quot;regression&quot;</span>,</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    eval_metric<span class="op">=</span><span class="st">&quot;r2&quot;</span>,</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    learner_kwargs<span class="op">=</span>{<span class="st">&quot;ignored_columns&quot;</span>: [<span class="st">&quot;casual&quot;</span>, <span class="st">&quot;registered&quot;</span>]}</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>predictor.fit(</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    train_data<span class="op">=</span>train,</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    time_limit<span class="op">=</span><span class="dv">600</span>, </span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    presets<span class="op">=</span><span class="st">&quot;best_quality&quot;</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230531_185520/&quot;
Presets specified: [&#39;best_quality&#39;]
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 600s
AutoGluon will save models to &quot;AutogluonModels/ag-20230531_185520/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.10
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat May 20 10:48:19 UTC 2023
Train Data Rows:    10886
Train Data Columns: 11
Label Column: count
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Dropping user-specified ignored columns: [&#39;casual&#39;, &#39;registered&#39;]
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    32221.97 MB
	Train Data (Original)  Memory Usage: 1.52 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 2 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;float&#39;, [])                      : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                        : 5 | [&#39;season&#39;, &#39;holiday&#39;, &#39;workingday&#39;, &#39;weather&#39;, &#39;humidity&#39;]
		(&#39;object&#39;, [&#39;datetime_as_object&#39;]) : 1 | [&#39;datetime&#39;]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 3 | [&#39;season&#39;, &#39;weather&#39;, &#39;humidity&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 2 | [&#39;holiday&#39;, &#39;workingday&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.1s = Fit runtime
	9 features in original data used to generate 13 features in processed data.
	Train Data (Processed) Memory Usage: 0.98 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.13s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;r2&#39;
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 2 stack levels (L1 to L2) ...
Fitting 11 L1 models ...
Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.81s of the 599.86s of remaining time.
	0.6851	 = Validation score   (r2)
	0.66s	 = Training   runtime
	0.04s	 = Validation runtime
Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 396.31s of the 596.36s of remaining time.
	0.784	 = Validation score   (r2)
	0.02s	 = Training   runtime
	0.04s	 = Validation runtime
Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 396.22s of the 596.27s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	0.4733	 = Validation score   (r2)
	133.18s	 = Training   runtime
	18.83s	 = Validation runtime
Fitting model: LightGBM_BAG_L1 ... Training model for up to 242.2s of the 442.25s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	0.4765	 = Validation score   (r2)
	66.5s	 = Training   runtime
	6.73s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 161.54s of the 361.59s of remaining time.
	0.586	 = Validation score   (r2)
	17.76s	 = Training   runtime
	0.63s	 = Validation runtime
Fitting model: CatBoost_BAG_L1 ... Training model for up to 142.11s of the 342.16s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	0.4753	 = Validation score   (r2)
	130.07s	 = Training   runtime
	0.19s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 198.93s of remaining time.
	0.784	 = Validation score   (r2)
	0.45s	 = Training   runtime
	0.0s	 = Validation runtime
Fitting 9 L2 models ...
Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 198.47s of the 198.46s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	0.8887	 = Validation score   (r2)
	106.47s	 = Training   runtime
	11.32s	 = Validation runtime
Fitting model: LightGBM_BAG_L2 ... Training model for up to 75.06s of the 75.05s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	0.9085	 = Validation score   (r2)
	42.8s	 = Training   runtime
	0.96s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 18.03s of the 18.02s of remaining time.
	0.9141	 = Validation score   (r2)
	40.71s	 = Training   runtime
	0.66s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -23.95s of remaining time.
	0.9151	 = Validation score   (r2)
	0.22s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 624.19s ... Best model: &quot;WeightedEnsemble_L3&quot;
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230531_185520/&quot;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="11">
<pre><code>&lt;autogluon.tabular.predictor.predictor.TabularPredictor at 0x7b601646a9e0&gt;</code></pre>
</div>
</div>
<section
id="review-autogluons-training-run-with-ranking-of-models-that-did-the-best"
class="cell markdown">
<h3>Review AutoGluon's training run with ranking of models that did the
best.</h3>
</section>
<div class="cell code" data-execution_count="12"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:05:45.140633Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:05:45.139671Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:05:45.341452Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:05:45.340470Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:05:45.140594Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>predictor.fit_summary()</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/opt/conda/lib/python3.10/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                     model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0      WeightedEnsemble_L3   0.915086      39.408947  538.387561                0.000742           0.215110            3       True         11
1   RandomForestMSE_BAG_L2   0.914105      27.129649  388.903521                0.661290          40.709336            2       True         10
2          LightGBM_BAG_L2   0.908477      27.425242  390.989773                0.956883          42.795588            2       True          9
3        LightGBMXT_BAG_L2   0.888671      37.790030  454.667527               11.321672         106.473342            2       True          8
4    KNeighborsDist_BAG_L1   0.784046       0.044210    0.022138                0.044210           0.022138            1       True          2
5      WeightedEnsemble_L2   0.784046       0.044937    0.473155                0.000726           0.451017            2       True          7
6    KNeighborsUnif_BAG_L1   0.685112       0.038013    0.660600                0.038013           0.660600            1       True          1
7   RandomForestMSE_BAG_L1   0.585998       0.634355   17.758662                0.634355          17.758662            1       True          5
8          LightGBM_BAG_L1   0.476532       6.731662   66.497870                6.731662          66.497870            1       True          4
9          CatBoost_BAG_L1   0.475278       0.188191  130.071753                0.188191         130.071753            1       True          6
10       LightGBMXT_BAG_L1   0.473256      18.831928  133.183162               18.831928         133.183162            1       True          3
Number of models trained: 11
Types of models trained:
{&#39;StackerEnsembleModel_RF&#39;, &#39;StackerEnsembleModel_KNN&#39;, &#39;StackerEnsembleModel_CatBoost&#39;, &#39;WeightedEnsembleModel&#39;, &#39;StackerEnsembleModel_LGB&#39;}
Bagging used: True  (with 8 folds)
Multi-layer stack-ensembling used: True  (with 3 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 3 | [&#39;season&#39;, &#39;weather&#39;, &#39;humidity&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 2 | [&#39;holiday&#39;, &#39;workingday&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output execute_result" data-execution_count="12">
<pre><code>{&#39;model_types&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.6851116791019343,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.7840462130977728,
  &#39;LightGBMXT_BAG_L1&#39;: 0.4732562269834053,
  &#39;LightGBM_BAG_L1&#39;: 0.476531925532341,
  &#39;RandomForestMSE_BAG_L1&#39;: 0.5859982828970275,
  &#39;CatBoost_BAG_L1&#39;: 0.4752778595430499,
  &#39;WeightedEnsemble_L2&#39;: 0.7840462130977728,
  &#39;LightGBMXT_BAG_L2&#39;: 0.8886712579725276,
  &#39;LightGBM_BAG_L2&#39;: 0.9084768594801632,
  &#39;RandomForestMSE_BAG_L2&#39;: 0.9141053063173007,
  &#39;WeightedEnsemble_L3&#39;: 0.9150858441075591},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L3&#39;,
 &#39;model_paths&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_185520/models/KNeighborsUnif_BAG_L1/&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_185520/models/KNeighborsDist_BAG_L1/&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_185520/models/LightGBMXT_BAG_L1/&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_185520/models/LightGBM_BAG_L1/&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_185520/models/RandomForestMSE_BAG_L1/&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_185520/models/CatBoost_BAG_L1/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230531_185520/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;AutogluonModels/ag-20230531_185520/models/LightGBMXT_BAG_L2/&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;AutogluonModels/ag-20230531_185520/models/LightGBM_BAG_L2/&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;AutogluonModels/ag-20230531_185520/models/RandomForestMSE_BAG_L2/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230531_185520/models/WeightedEnsemble_L3/&#39;},
 &#39;model_fit_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.6605997085571289,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.022138118743896484,
  &#39;LightGBMXT_BAG_L1&#39;: 133.18316197395325,
  &#39;LightGBM_BAG_L1&#39;: 66.49787020683289,
  &#39;RandomForestMSE_BAG_L1&#39;: 17.75866198539734,
  &#39;CatBoost_BAG_L1&#39;: 130.07175302505493,
  &#39;WeightedEnsemble_L2&#39;: 0.451016902923584,
  &#39;LightGBMXT_BAG_L2&#39;: 106.47334170341492,
  &#39;LightGBM_BAG_L2&#39;: 42.79558777809143,
  &#39;RandomForestMSE_BAG_L2&#39;: 40.709336280822754,
  &#39;WeightedEnsemble_L3&#39;: 0.21511030197143555},
 &#39;model_pred_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.03801274299621582,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.04421043395996094,
  &#39;LightGBMXT_BAG_L1&#39;: 18.83192777633667,
  &#39;LightGBM_BAG_L1&#39;: 6.731661558151245,
  &#39;RandomForestMSE_BAG_L1&#39;: 0.634354829788208,
  &#39;CatBoost_BAG_L1&#39;: 0.18819117546081543,
  &#39;WeightedEnsemble_L2&#39;: 0.0007262229919433594,
  &#39;LightGBMXT_BAG_L2&#39;: 11.321671962738037,
  &#39;LightGBM_BAG_L2&#39;: 0.956883430480957,
  &#39;RandomForestMSE_BAG_L2&#39;: 0.6612904071807861,
  &#39;WeightedEnsemble_L3&#39;: 0.0007424354553222656},
 &#39;num_bag_folds&#39;: 8,
 &#39;max_stack_level&#39;: 3,
 &#39;model_hyperparams&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;KNeighborsDist_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;LightGBMXT_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBMXT_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                      model  score_val  pred_time_val    fit_time  \
 0      WeightedEnsemble_L3   0.915086      39.408947  538.387561   
 1   RandomForestMSE_BAG_L2   0.914105      27.129649  388.903521   
 2          LightGBM_BAG_L2   0.908477      27.425242  390.989773   
 3        LightGBMXT_BAG_L2   0.888671      37.790030  454.667527   
 4    KNeighborsDist_BAG_L1   0.784046       0.044210    0.022138   
 5      WeightedEnsemble_L2   0.784046       0.044937    0.473155   
 6    KNeighborsUnif_BAG_L1   0.685112       0.038013    0.660600   
 7   RandomForestMSE_BAG_L1   0.585998       0.634355   17.758662   
 8          LightGBM_BAG_L1   0.476532       6.731662   66.497870   
 9          CatBoost_BAG_L1   0.475278       0.188191  130.071753   
 10       LightGBMXT_BAG_L1   0.473256      18.831928  133.183162   
 
     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                 0.000742           0.215110            3       True   
 1                 0.661290          40.709336            2       True   
 2                 0.956883          42.795588            2       True   
 3                11.321672         106.473342            2       True   
 4                 0.044210           0.022138            1       True   
 5                 0.000726           0.451017            2       True   
 6                 0.038013           0.660600            1       True   
 7                 0.634355          17.758662            1       True   
 8                 6.731662          66.497870            1       True   
 9                 0.188191         130.071753            1       True   
 10               18.831928         133.183162            1       True   
 
     fit_order  
 0          11  
 1          10  
 2           9  
 3           8  
 4           2  
 5           7  
 6           1  
 7           5  
 8           4  
 9           6  
 10          3  }</code></pre>
</div>
</div>
<section id="create-predictions-from-test-dataset"
class="cell markdown">
<h3>Create predictions from test dataset</h3>
</section>
<div class="cell code" data-execution_count="13"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:05:45.343046Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:05:45.342737Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:06:41.823293Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:06:41.822151Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:05:45.343019Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> predictor.predict(test)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>predictions.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="13">
<pre><code>0    25.552622
1    45.372406
2    52.261803
3    55.435040
4    57.927185
Name: count, dtype: float32</code></pre>
</div>
</div>
<section
id="note-kaggle-will-reject-the-submission-if-we-dont-set-everything-to-be--0"
class="cell markdown">
<h4>NOTE: Kaggle will reject the submission if we don't set everything
to be &gt; 0.</h4>
</section>
<div class="cell code" data-execution_count="14"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:06:41.824910Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:06:41.824593Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:06:42.295639Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:06:42.294624Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:06:41.824882Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Describe the `predictions` series to see if there are any negative values</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>predictor.leaderboard(silent<span class="op">=</span><span class="va">True</span>).plot(kind<span class="op">=</span><span class="st">&quot;bar&quot;</span>, x<span class="op">=</span><span class="st">&quot;model&quot;</span>, y<span class="op">=</span><span class="st">&quot;score_val&quot;</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="14">
<pre><code>&lt;Axes: xlabel=&#39;model&#39;&gt;</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_5a3329f1f7c34305ae70eb667a8aba9d/ca56b16ee6140f61a6919a413c4e219876e764bd.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="15"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:06:42.297747Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:06:42.297451Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:06:42.308815Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:06:42.307999Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:06:42.297722Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># How many negative values do we have?</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>predictions.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="15">
<pre><code>count    6493.000000
mean      119.582878
std       113.472733
min         3.171033
25%        21.445763
50%        73.455276
75%       200.976135
max       434.809479
Name: count, dtype: float64</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="16"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:06:42.310836Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:06:42.310105Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:06:42.317908Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:06:42.316893Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:06:42.310798Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set them to zero</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>predictions[predictions <span class="op">&lt;</span> <span class="dv">0</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(predictions[predictions <span class="op">&lt;</span> <span class="dv">0</span>].shape)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>(0,)
</code></pre>
</div>
</div>
<section id="set-predictions-to-submission-dataframe-save-and-submit"
class="cell markdown">
<h3>Set predictions to submission dataframe, save, and submit</h3>
</section>
<div class="cell code" data-execution_count="17"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:06:42.319779Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:06:42.319419Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:06:42.345822Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:06:42.345015Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:06:42.319746Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>submission[<span class="st">&quot;count&quot;</span>] <span class="op">=</span> predictions.values</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>submission.to_csv(<span class="st">&quot;submission.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="18"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:06:42.347679Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:06:42.347268Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:06:42.364575Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:06:42.359576Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:06:42.347643Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>submission</span></code></pre></div>
<div class="output execute_result" data-execution_count="18">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-20 00:00:00</td>
      <td>25.552622</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-20 01:00:00</td>
      <td>45.372406</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-20 02:00:00</td>
      <td>52.261803</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-20 03:00:00</td>
      <td>55.435040</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-20 04:00:00</td>
      <td>57.927185</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>6488</th>
      <td>2012-12-31 19:00:00</td>
      <td>247.282349</td>
    </tr>
    <tr>
      <th>6489</th>
      <td>2012-12-31 20:00:00</td>
      <td>247.282349</td>
    </tr>
    <tr>
      <th>6490</th>
      <td>2012-12-31 21:00:00</td>
      <td>250.678223</td>
    </tr>
    <tr>
      <th>6491</th>
      <td>2012-12-31 22:00:00</td>
      <td>239.515839</td>
    </tr>
    <tr>
      <th>6492</th>
      <td>2012-12-31 23:00:00</td>
      <td>249.405441</td>
    </tr>
  </tbody>
</table>
<p>6493 rows × 2 columns</p>
</div>
</div>
</div>
<div class="cell code" data-execution_count="19"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:06:42.366270Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:06:42.366009Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:06:47.986135Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:06:47.985080Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:06:42.366247Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submit <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">-</span>f submission.csv <span class="op">-</span>m <span class="st">&quot;third raw submission&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>100%|████████████████████████████████████████| 188k/188k [00:02&lt;00:00, 73.0kB/s]
Successfully submitted to Bike Sharing Demand</code></pre>
</div>
</div>
<section
id="view-submission-via-the-command-line-or-in-the-web-browser-under-the-competitions-page---my-submissions"
class="cell markdown">
<h4>View submission via the command line or in the web browser under the
competition's page - <code>My Submissions</code></h4>
</section>
<div class="cell code" data-execution_count="20"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:06:47.988814Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:06:47.988107Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:06:49.994821Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:06:49.993699Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:06:47.988773Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submissions <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">|</span> tail <span class="op">-</span>n <span class="op">+</span><span class="dv">1</span> <span class="op">|</span> head <span class="op">-</span>n <span class="dv">6</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>fileName                     date                 description                        status    publicScore  privateScore  
---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  
submission.csv               2023-05-31 19:06:46  third raw submission               complete  1.85631      1.85631       
submission_new_hpo.csv       2023-05-31 17:33:43  new features with hyperparameters  complete  1.33537      1.33537       
submission_new_features.csv  2023-05-31 16:38:05  new features 3_2                   complete  1.87731      1.87731       
submission.csv               2023-05-31 16:26:28  third raw submission               complete  1.88526      1.88526       
</code></pre>
</div>
</div>
<section id="initial-score-of-18" class="cell markdown">
<h4>Initial score of <code>1.8</code></h4>
</section>
<section
id="step-4-exploratory-data-analysis-and-creating-an-additional-feature"
class="cell markdown">
<h2>Step 4: Exploratory Data Analysis and Creating an additional
feature</h2>
<ul>
<li>Any additional feature will do, but a great suggestion would be to
separate out the datetime into hour, day, or month parts.</li>
</ul>
</section>
<div class="cell code" data-execution_count="21"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:06:49.996618Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:06:49.996310Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:06:52.268355Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:06:52.267168Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:06:49.996584Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a histogram of all features to show the distribution of each one relative to the data. This is part of the exploritory data analysis</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>train.hist(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))<span class="op">;</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_5a3329f1f7c34305ae70eb667a8aba9d/58e7834f12cd8c6630bea06b95dbb21ddb8a731d.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="22"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:06:52.270435Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:06:52.270033Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:06:52.282228Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:06:52.281158Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:06:52.270403Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create a new feature</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&quot;season&quot;</span>] <span class="op">=</span> train[<span class="st">&quot;season&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&quot;weather&quot;</span>] <span class="op">=</span> train[<span class="st">&quot;weather&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&quot;season&quot;</span>] <span class="op">=</span> test[<span class="st">&quot;season&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&quot;weather&quot;</span>] <span class="op">=</span> test[<span class="st">&quot;weather&quot;</span>].astype(<span class="st">&quot;category&quot;</span>)</span></code></pre></div>
</div>
<section
id="make-category-types-for-these-so-models-know-they-are-not-just-numbers"
class="cell markdown">
<h2>Make category types for these so models know they are not just
numbers</h2>
<ul>
<li>AutoGluon originally sees these as ints, but in reality they are int
representations of a category.</li>
<li>Setting the dtype to category will classify these as categories in
AutoGluon.</li>
</ul>
</section>
<div class="cell code" data-execution_count="24"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:08:57.646741Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:08:57.646171Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:08:57.691371Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:08:57.690274Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:08:57.646706Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;datetime&#39;</span>] <span class="op">=</span> pd.to_datetime(train[ <span class="st">&#39;datetime&#39;</span>])</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;year&#39;</span>] <span class="op">=</span> train.datetime.dt.year</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;month&#39;</span>] <span class="op">=</span> train.datetime.dt.month</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;day&#39;</span>] <span class="op">=</span> train.datetime.dt.day</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&quot;hour&quot;</span>] <span class="op">=</span> train.datetime.dt.hour</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;datetime&#39;</span>] <span class="op">=</span> pd.to_datetime(test[ <span class="st">&#39;datetime&#39;</span>])</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;year&#39;</span>] <span class="op">=</span> test.datetime.dt.year</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;month&#39;</span>] <span class="op">=</span> test.datetime.dt.month</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;day&#39;</span>] <span class="op">=</span> test.datetime.dt.day</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&quot;hour&quot;</span>] <span class="op">=</span> test.datetime.dt.hour</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="25"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:11:02.390160Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:11:02.389660Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:11:02.412456Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:11:02.411425Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:11:02.390115Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View are new feature</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>train.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="25">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>hour</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-01 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>81</td>
      <td>0.0</td>
      <td>3</td>
      <td>13</td>
      <td>16</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-01 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>8</td>
      <td>32</td>
      <td>40</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-01 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>5</td>
      <td>27</td>
      <td>32</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-01 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>3</td>
      <td>10</td>
      <td>13</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-01 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="26"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:11:04.934890Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:11:04.934114Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:11:07.828277Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:11:07.827216Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:11:04.934849Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View histogram of all features again now with the hour feature</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>train.hist(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))<span class="op">;</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_5a3329f1f7c34305ae70eb667a8aba9d/ad137f99e5af847a6b9b0f8758f710281fd7337d.png" /></p>
</div>
</div>
<section
id="step-5-rerun-the-model-with-the-same-settings-as-before-just-with-more-features"
class="cell markdown">
<h2>Step 5: Rerun the model with the same settings as before, just with
more features</h2>
</section>
<div class="cell code" data-execution_count="27"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:11:11.262911Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:11:11.262498Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:21:44.092574Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:21:44.091524Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:11:11.262881Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>predictor_new_features <span class="op">=</span> TabularPredictor(</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">&quot;count&quot;</span>,</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    problem_type<span class="op">=</span><span class="st">&quot;regression&quot;</span>,</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    eval_metric<span class="op">=</span><span class="st">&quot;r2&quot;</span>,</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>    learner_kwargs<span class="op">=</span>{<span class="st">&quot;ignored_columns&quot;</span>: [<span class="st">&quot;casual&quot;</span>, <span class="st">&quot;registered&quot;</span>]}</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>predictor_new_features.fit(</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>    train_data<span class="op">=</span>train,</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    time_limit<span class="op">=</span><span class="dv">600</span>, </span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>    presets<span class="op">=</span><span class="st">&quot;best_quality&quot;</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230531_191111/&quot;
Presets specified: [&#39;best_quality&#39;]
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 600s
AutoGluon will save models to &quot;AutogluonModels/ag-20230531_191111/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.10
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat May 20 10:48:19 UTC 2023
Train Data Rows:    10886
Train Data Columns: 15
Label Column: count
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Dropping user-specified ignored columns: [&#39;casual&#39;, &#39;registered&#39;]
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    31358.6 MB
	Train Data (Original)  Memory Usage: 0.98 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 3 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting CategoryFeatureGenerator...
			Fitting CategoryMemoryMinimizeFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;category&#39;, []) : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;datetime&#39;, []) : 1 | [&#39;datetime&#39;]
		(&#39;float&#39;, [])    : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])      : 7 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;humidity&#39;, &#39;year&#39;, &#39;month&#39;, ...]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.1s = Fit runtime
	13 features in original data used to generate 17 features in processed data.
	Train Data (Processed) Memory Usage: 1.1 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.15s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;r2&#39;
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 2 stack levels (L1 to L2) ...
Fitting 11 L1 models ...
Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.8s of the 599.84s of remaining time.
	0.6851	 = Validation score   (r2)
	0.02s	 = Training   runtime
	0.04s	 = Validation runtime
Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 399.7s of the 599.75s of remaining time.
	0.784	 = Validation score   (r2)
	0.02s	 = Training   runtime
	0.04s	 = Validation runtime
Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 399.61s of the 599.66s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	0.964	 = Validation score   (r2)
	205.86s	 = Training   runtime
	37.82s	 = Validation runtime
Fitting model: LightGBM_BAG_L1 ... Training model for up to 176.78s of the 376.83s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	0.9649	 = Validation score   (r2)
	100.92s	 = Training   runtime
	11.54s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 60.38s of the 260.42s of remaining time.
	0.9553	 = Validation score   (r2)
	23.66s	 = Training   runtime
	0.64s	 = Validation runtime
Fitting model: CatBoost_BAG_L1 ... Training model for up to 35.45s of the 235.5s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	0.9356	 = Validation score   (r2)
	45.59s	 = Training   runtime
	0.89s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 175.64s of remaining time.
	0.9682	 = Validation score   (r2)
	0.51s	 = Training   runtime
	0.0s	 = Validation runtime
Fitting 9 L2 models ...
Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 175.12s of the 175.11s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	0.9703	 = Validation score   (r2)
	70.14s	 = Training   runtime
	2.36s	 = Validation runtime
Fitting model: LightGBM_BAG_L2 ... Training model for up to 87.3s of the 87.29s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	0.9714	 = Validation score   (r2)
	52.26s	 = Training   runtime
	2.2s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 18.82s of the 18.81s of remaining time.
	0.9692	 = Validation score   (r2)
	49.95s	 = Training   runtime
	0.72s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -32.53s of remaining time.
	0.9718	 = Validation score   (r2)
	0.23s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 632.79s ... Best model: &quot;WeightedEnsemble_L3&quot;
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230531_191111/&quot;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="27">
<pre><code>&lt;autogluon.tabular.predictor.predictor.TabularPredictor at 0x7b5cb08c33a0&gt;</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="28"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:21:44.095353Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:21:44.094890Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:21:44.133311Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:21:44.132192Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:21:44.095292Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>predictor_new_features.fit_summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                     model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0      WeightedEnsemble_L3   0.971810      56.257819  548.653626                0.000797           0.231445            3       True         11
1          LightGBM_BAG_L2   0.971430      53.174174  428.336195                2.196360          52.258215            2       True          9
2        LightGBMXT_BAG_L2   0.970279      53.337461  446.213606                2.359646          70.135627            2       True          8
3   RandomForestMSE_BAG_L2   0.969247      51.701017  426.028338                0.723202          49.950359            2       True         10
4      WeightedEnsemble_L2   0.968176      50.048134  330.973250                0.000786           0.507725            2       True          7
5          LightGBM_BAG_L1   0.964932      11.536744  100.924181               11.536744         100.924181            1       True          4
6        LightGBMXT_BAG_L1   0.964040      37.823311  205.856359               37.823311         205.856359            1       True          3
7   RandomForestMSE_BAG_L1   0.955277       0.642799   23.662646                0.642799          23.662646            1       True          5
8          CatBoost_BAG_L1   0.935639       0.886097   45.588474                0.886097          45.588474            1       True          6
9    KNeighborsDist_BAG_L1   0.784046       0.044494    0.022339                0.044494           0.022339            1       True          2
10   KNeighborsUnif_BAG_L1   0.685112       0.044370    0.023980                0.044370           0.023980            1       True          1
Number of models trained: 11
Types of models trained:
{&#39;StackerEnsembleModel_RF&#39;, &#39;StackerEnsembleModel_KNN&#39;, &#39;StackerEnsembleModel_CatBoost&#39;, &#39;WeightedEnsembleModel&#39;, &#39;StackerEnsembleModel_LGB&#39;}
Bagging used: True  (with 8 folds)
Multi-layer stack-ensembling used: True  (with 3 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/opt/conda/lib/python3.10/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="28">
<pre><code>{&#39;model_types&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.6851116791019343,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.7840462130977728,
  &#39;LightGBMXT_BAG_L1&#39;: 0.9640404931532589,
  &#39;LightGBM_BAG_L1&#39;: 0.9649317012151711,
  &#39;RandomForestMSE_BAG_L1&#39;: 0.9552774921753547,
  &#39;CatBoost_BAG_L1&#39;: 0.9356387882347352,
  &#39;WeightedEnsemble_L2&#39;: 0.9681759250754284,
  &#39;LightGBMXT_BAG_L2&#39;: 0.9702786677815413,
  &#39;LightGBM_BAG_L2&#39;: 0.9714303620210075,
  &#39;RandomForestMSE_BAG_L2&#39;: 0.9692472350833382,
  &#39;WeightedEnsemble_L3&#39;: 0.9718099411474068},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L3&#39;,
 &#39;model_paths&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_191111/models/KNeighborsUnif_BAG_L1/&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_191111/models/KNeighborsDist_BAG_L1/&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_191111/models/LightGBMXT_BAG_L1/&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_191111/models/LightGBM_BAG_L1/&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_191111/models/RandomForestMSE_BAG_L1/&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;AutogluonModels/ag-20230531_191111/models/CatBoost_BAG_L1/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230531_191111/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;AutogluonModels/ag-20230531_191111/models/LightGBMXT_BAG_L2/&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;AutogluonModels/ag-20230531_191111/models/LightGBM_BAG_L2/&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;AutogluonModels/ag-20230531_191111/models/RandomForestMSE_BAG_L2/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230531_191111/models/WeightedEnsemble_L3/&#39;},
 &#39;model_fit_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.023980379104614258,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.0223388671875,
  &#39;LightGBMXT_BAG_L1&#39;: 205.85635924339294,
  &#39;LightGBM_BAG_L1&#39;: 100.92418098449707,
  &#39;RandomForestMSE_BAG_L1&#39;: 23.66264581680298,
  &#39;CatBoost_BAG_L1&#39;: 45.58847403526306,
  &#39;WeightedEnsemble_L2&#39;: 0.5077254772186279,
  &#39;LightGBMXT_BAG_L2&#39;: 70.13562679290771,
  &#39;LightGBM_BAG_L2&#39;: 52.25821542739868,
  &#39;RandomForestMSE_BAG_L2&#39;: 49.95035910606384,
  &#39;WeightedEnsemble_L3&#39;: 0.2314453125},
 &#39;model_pred_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.044370174407958984,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.0444943904876709,
  &#39;LightGBMXT_BAG_L1&#39;: 37.8233106136322,
  &#39;LightGBM_BAG_L1&#39;: 11.536743879318237,
  &#39;RandomForestMSE_BAG_L1&#39;: 0.642798662185669,
  &#39;CatBoost_BAG_L1&#39;: 0.8860969543457031,
  &#39;WeightedEnsemble_L2&#39;: 0.0007860660552978516,
  &#39;LightGBMXT_BAG_L2&#39;: 2.3596458435058594,
  &#39;LightGBM_BAG_L2&#39;: 2.196359634399414,
  &#39;RandomForestMSE_BAG_L2&#39;: 0.7232022285461426,
  &#39;WeightedEnsemble_L3&#39;: 0.0007970333099365234},
 &#39;num_bag_folds&#39;: 8,
 &#39;max_stack_level&#39;: 3,
 &#39;model_hyperparams&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;KNeighborsDist_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;LightGBMXT_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBMXT_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                      model  score_val  pred_time_val    fit_time  \
 0      WeightedEnsemble_L3   0.971810      56.257819  548.653626   
 1          LightGBM_BAG_L2   0.971430      53.174174  428.336195   
 2        LightGBMXT_BAG_L2   0.970279      53.337461  446.213606   
 3   RandomForestMSE_BAG_L2   0.969247      51.701017  426.028338   
 4      WeightedEnsemble_L2   0.968176      50.048134  330.973250   
 5          LightGBM_BAG_L1   0.964932      11.536744  100.924181   
 6        LightGBMXT_BAG_L1   0.964040      37.823311  205.856359   
 7   RandomForestMSE_BAG_L1   0.955277       0.642799   23.662646   
 8          CatBoost_BAG_L1   0.935639       0.886097   45.588474   
 9    KNeighborsDist_BAG_L1   0.784046       0.044494    0.022339   
 10   KNeighborsUnif_BAG_L1   0.685112       0.044370    0.023980   
 
     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                 0.000797           0.231445            3       True   
 1                 2.196360          52.258215            2       True   
 2                 2.359646          70.135627            2       True   
 3                 0.723202          49.950359            2       True   
 4                 0.000786           0.507725            2       True   
 5                11.536744         100.924181            1       True   
 6                37.823311         205.856359            1       True   
 7                 0.642799          23.662646            1       True   
 8                 0.886097          45.588474            1       True   
 9                 0.044494           0.022339            1       True   
 10                0.044370           0.023980            1       True   
 
     fit_order  
 0          11  
 1           9  
 2           8  
 3          10  
 4           7  
 5           4  
 6           3  
 7           5  
 8           6  
 9           2  
 10          1  }</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="29"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:21:44.135495Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:21:44.135087Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:22:50.927160Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:22:50.926016Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:21:44.135458Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb45"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>predictions_new_features <span class="op">=</span> predictor_new_features.predict(test)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>predictions_new_features.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="29">
<pre><code>0    17.465321
1    12.793571
2    11.416145
3     9.278634
4     8.478694
Name: count, dtype: float32</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="30"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:22:50.929698Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:22:50.929399Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:22:50.976520Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:22:50.975636Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:22:50.929672Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb47"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remember to set all negative values to zero</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(predictions_new_features)):</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> predictions_new_features[i] <span class="op">&lt;</span> <span class="dv">0</span>:</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>        predictions_new_features[i]<span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="31"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:22:50.978164Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:22:50.977705Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:22:50.989726Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:22:50.988689Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:22:50.978136Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>submission_new_features <span class="op">=</span> pd.read_csv(<span class="st">&quot;/kaggle/working/submission.csv&quot;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="32"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:22:50.991617Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:22:50.991286Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:22:51.019248Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:22:51.017992Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:22:50.991582Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb49"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same submitting predictions</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>submission_new_features[<span class="st">&quot;count&quot;</span>] <span class="op">=</span> predictions_new_features.values</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>submission_new_features.to_csv(<span class="st">&quot;submission_new_features.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="33"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:22:51.021062Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:22:51.020587Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:22:56.164784Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:22:56.163539Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:22:51.021033Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submit <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">-</span>f submission_new_features.csv <span class="op">-</span>m <span class="st">&quot;new features 3_2&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>100%|████████████████████████████████████████| 188k/188k [00:02&lt;00:00, 80.5kB/s]
Successfully submitted to Bike Sharing Demand</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="35"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:28:26.825727Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:28:26.825199Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:28:28.787917Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:28:28.786095Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:28:26.825685Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submissions <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">|</span> tail <span class="op">-</span>n <span class="op">+</span><span class="dv">1</span> <span class="op">|</span> head <span class="op">-</span>n <span class="dv">6</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>fileName                     date                 description                        status    publicScore  privateScore  
---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  
submission_new_features.csv  2023-05-31 19:22:55  new features 3_2                   complete  0.64166      0.64166       
submission.csv               2023-05-31 19:06:46  third raw submission               complete  1.85631      1.85631       
submission_new_hpo.csv       2023-05-31 17:33:43  new features with hyperparameters  complete  1.33537      1.33537       
submission_new_features.csv  2023-05-31 16:38:05  new features 3_2                   complete  1.87731      1.87731       
</code></pre>
</div>
</div>
<section id="new-score-of-064" class="cell markdown">
<h4>New Score of <code>0.64</code></h4>
</section>
<section id="step-6-hyper-parameter-optimization" class="cell markdown">
<h2>Step 6: Hyper parameter optimization</h2>
<ul>
<li>There are many options for hyper parameter optimization.</li>
<li>Options are to change the AutoGluon higher level parameters or the
individual model hyperparameters.</li>
<li>The hyperparameters of the models themselves that are in AutoGluon.
Those need the <code>hyperparameter</code> and
<code>hyperparameter_tune_kwargs</code> arguments.</li>
</ul>
</section>
<div class="cell code" data-execution_count="36"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:29:03.580025Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:29:03.579562Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:29:03.592257Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:29:03.590643Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:29:03.579981Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>train.drop([<span class="st">&#39;casual&#39;</span>, <span class="st">&#39;registered&#39;</span>], axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="37"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:29:04.611922Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:29:04.611167Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:37:49.687124Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:37:49.686033Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:29:04.611886Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb55"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>num_trials <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>search_strategy <span class="op">=</span> <span class="st">&#39;auto&#39;</span></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>hyperparameters <span class="op">=</span> {</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;NN&#39;</span>: {<span class="st">&#39;num_epochs&#39;</span>: <span class="dv">10</span> <span class="st">&#39;batch_size&#39;</span>: <span class="dv">32</span>}, </span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;GBM&#39;</span>: {<span class="st">&#39;num_boost_round&#39;</span>: <span class="dv">50</span>}</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>hyperparameter_tune_kwargs <span class="op">=</span> { </span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;num_trials&#39;</span>: num_trials,</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;scheduler&#39;</span> : <span class="st">&#39;local&#39;</span>,</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;searcher&#39;</span>: search_strategy,</span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>predictor_new_hpo <span class="op">=</span> TabularPredictor(</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a>      label<span class="op">=</span><span class="st">&quot;count&quot;</span>, </span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a>      problem_type<span class="op">=</span><span class="st">&quot;regression&quot;</span>, </span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a>      eval_metric<span class="op">=</span><span class="st">&quot;root_mean_squared_error&quot;</span>, </span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a>      learner_kwargs<span class="op">=</span>{<span class="st">&quot;ignored_columns&quot;</span>: [<span class="st">&quot;casual&quot;</span>, <span class="st">&quot;registered&quot;</span>]}</span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a>  ).fit(</span>
<span id="cb55-18"><a href="#cb55-18" aria-hidden="true" tabindex="-1"></a>      train_data<span class="op">=</span>train, time_limit<span class="op">=</span><span class="dv">1000</span>, presets<span class="op">=</span><span class="st">&quot;best_quality&quot;</span>, hyperparameters<span class="op">=</span>hyperparameters, hyperparameter_tune_kwargs<span class="op">=</span>hyperparameter_tune_kwargs</span>
<span id="cb55-19"><a href="#cb55-19" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230531_192904/&quot;
Presets specified: [&#39;best_quality&#39;]
Warning: hyperparameter tuning is currently experimental and may cause the process to hang.
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 600s
AutoGluon will save models to &quot;AutogluonModels/ag-20230531_192904/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.10
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat May 20 10:48:19 UTC 2023
Train Data Rows:    10886
Train Data Columns: 13
Label Column: count
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Dropping user-specified ignored columns: [&#39;casual&#39;, &#39;registered&#39;]
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    31285.19 MB
	Train Data (Original)  Memory Usage: 0.98 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 3 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting CategoryFeatureGenerator...
			Fitting CategoryMemoryMinimizeFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;category&#39;, []) : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;datetime&#39;, []) : 1 | [&#39;datetime&#39;]
		(&#39;float&#39;, [])    : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])      : 7 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;humidity&#39;, &#39;year&#39;, &#39;month&#39;, ...]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.1s = Fit runtime
	13 features in original data used to generate 17 features in processed data.
	Train Data (Processed) Memory Usage: 1.1 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.17s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;root_mean_squared_error&#39;
	This metric&#39;s sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 2 stack levels (L1 to L2) ...
	WARNING: &quot;NN&quot; model has been deprecated in v0.4.0 and renamed to &quot;NN_MXNET&quot;. Starting in v0.6.0, specifying &quot;NN&quot; or &quot;NN_MXNET&quot; will raise an exception. Consider instead specifying &quot;NN_TORCH&quot;.
Fitting 2 L1 models ...
Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 179.91s of the 599.83s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb57"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;e6da98e31531483d9e38d745b08ef69d&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Stopping HPO to satisfy time limit...
Fitted model: LightGBM_BAG_L1/T1 ...
	-53.7857	 = Validation score   (-root_mean_squared_error)
	54.2s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L1/T2 ...
	-39.9606	 = Validation score   (-root_mean_squared_error)
	46.93s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L1/T3 ...
	-49.2372	 = Validation score   (-root_mean_squared_error)
	44.92s	 = Training   runtime
	0.0s	 = Validation runtime
Hyperparameter tuning model: NeuralNetMXNet_BAG_L1 ... Tuning model for up to 179.91s of the 453.68s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb59"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;250d9d2c38654a46ae14a22ebd5fdec5&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=4263, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=4263, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-31 19:31:54,044	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=4264, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-31 19:31:54,055	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=4262, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-31 19:31:54,056	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=4261, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=4400, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=4400, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-31 19:32:16,460	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=4401, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-31 19:32:16,466	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=4399, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 19:32:18,753	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=4553, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=4553, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 19:32:40,603	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 19:32:40,734	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 19:32:40,860	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=4700, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=4700, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 19:33:01,303	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 19:33:01,575	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 19:33:01,719	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=4840, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=4840, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-31 19:33:19,891	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=4839, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-31 19:33:19,911	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=4837, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 19:33:22,324	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=4981, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=4981, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 19:33:44,343	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 19:33:44,627	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 19:33:44,640	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=5125, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=5125, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 19:34:02,670	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=5127, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-31 19:34:04,950	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 19:34:05,265	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=5270, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=5270, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Stopping HPO to satisfy time limit...
No model was trained during hyperparameter tuning NeuralNetMXNet_BAG_L1... Skipping this model.
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 280.45s of remaining time.
	-39.9606	 = Validation score   (-root_mean_squared_error)
	0.53s	 = Training   runtime
	0.0s	 = Validation runtime
	WARNING: &quot;NN&quot; model has been deprecated in v0.4.0 and renamed to &quot;NN_MXNET&quot;. Starting in v0.6.0, specifying &quot;NN&quot; or &quot;NN_MXNET&quot; will raise an exception. Consider instead specifying &quot;NN_TORCH&quot;.
Fitting 2 L2 models ...
Hyperparameter tuning model: LightGBM_BAG_L2 ... Tuning model for up to 125.95s of the 279.88s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb61"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;f65c5dd6a4274b3db3a93498fc75889a&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 19:34:26,524	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 19:34:26,547	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 19:34:26,659	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Stopping HPO to satisfy time limit...
Fitted model: LightGBM_BAG_L2/T1 ...
	-41.1304	 = Validation score   (-root_mean_squared_error)
	42.62s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L2/T2 ...
	-39.1754	 = Validation score   (-root_mean_squared_error)
	46.68s	 = Training   runtime
	0.0s	 = Validation runtime
Hyperparameter tuning model: NeuralNetMXNet_BAG_L2 ... Tuning model for up to 125.95s of the 190.44s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb63"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;2cb3adf3c3174a3abfddc9f1676d8ca6&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=5943, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=5943, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-31 19:36:17,634	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=5945, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 19:36:20,160	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 19:36:20,305	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=6078, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=6078, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 19:36:44,354	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 19:36:44,460	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 19:36:44,574	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=6250, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=6250, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-31 19:37:03,479	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=6248, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 19:37:05,824	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 19:37:05,981	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=6390, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=6390, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 19:37:28,304	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 19:37:28,429	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 19:37:28,883	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=6528, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=6528, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Stopping HPO to satisfy time limit...
No model was trained during hyperparameter tuning NeuralNetMXNet_BAG_L2... Skipping this model.
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 75.44s of remaining time.
2023-05-31 19:37:49,309	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=6527, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	-39.1754	 = Validation score   (-root_mean_squared_error)
	0.42s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 525.02s ... Best model: &quot;WeightedEnsemble_L3&quot;
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230531_192904/&quot;)
</code></pre>
</div>
</div>
<div class="cell code"
data-execution="{&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:06:53.489449Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:06:53.489783Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:06:53.489627Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:06:53.489611Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb65"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co">&quot;&quot;&quot;</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="co">predictor_new_hpo = TabularPredictor(label=&#39;count&#39;, eval_metric=&#39;root_mean_squared_error&#39;)</span><span class="ch">\</span></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a><span class="co">                    .fit(train_data=train, presets=&#39;best_quality&#39;, time_limit=600, verbosity=2, </span></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a><span class="co">                         hyperparameters=&#39;very_light&#39;, hyperparameter_tune_kwargs=&#39;auto&#39;,</span></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a><span class="co">                         auto_stack=True, num_bag_sets=10)</span></span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a><span class="co">                         </span></span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a><span class="co">&quot;&quot;&quot;</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="38"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:37:49.693073Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:37:49.692769Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:37:49.759789Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:37:49.758592Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:37:49.693045Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb66"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>predictor_new_hpo.fit_summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                 model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0   LightGBM_BAG_L2/T2 -39.175397       0.000593  192.719158                0.000144          46.677748            2       True          6
1  WeightedEnsemble_L3 -39.175397       0.001609  193.136351                0.001016           0.417192            3       True          7
2   LightGBM_BAG_L1/T2 -39.960581       0.000126   46.925775                0.000126          46.925775            1       True          2
3  WeightedEnsemble_L2 -39.960581       0.000867   47.459814                0.000741           0.534039            2       True          4
4   LightGBM_BAG_L2/T1 -41.130442       0.000564  188.657560                0.000115          42.616149            2       True          5
5   LightGBM_BAG_L1/T3 -49.237221       0.000130   44.920205                0.000130          44.920205            1       True          3
6   LightGBM_BAG_L1/T1 -53.785746       0.000193   54.195430                0.000193          54.195430            1       True          1
Number of models trained: 7
Types of models trained:
{&#39;WeightedEnsembleModel&#39;, &#39;StackerEnsembleModel_LGB&#39;}
Bagging used: True  (with 8 folds)
Multi-layer stack-ensembling used: True  (with 3 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/opt/conda/lib/python3.10/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="38">
<pre><code>{&#39;model_types&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T3&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBM_BAG_L2/T1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2/T2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: -53.785745858186026,
  &#39;LightGBM_BAG_L1/T2&#39;: -39.96058105317652,
  &#39;LightGBM_BAG_L1/T3&#39;: -49.23722071330252,
  &#39;WeightedEnsemble_L2&#39;: -39.96058105317652,
  &#39;LightGBM_BAG_L2/T1&#39;: -41.13044229721752,
  &#39;LightGBM_BAG_L2/T2&#39;: -39.17539675284323,
  &#39;WeightedEnsemble_L3&#39;: -39.17539675284323},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L3&#39;,
 &#39;model_paths&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: &#39;/kaggle/working/AutogluonModels/ag-20230531_192904/models/LightGBM_BAG_L1/T1/&#39;,
  &#39;LightGBM_BAG_L1/T2&#39;: &#39;/kaggle/working/AutogluonModels/ag-20230531_192904/models/LightGBM_BAG_L1/T2/&#39;,
  &#39;LightGBM_BAG_L1/T3&#39;: &#39;/kaggle/working/AutogluonModels/ag-20230531_192904/models/LightGBM_BAG_L1/T3/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230531_192904/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBM_BAG_L2/T1&#39;: &#39;/kaggle/working/AutogluonModels/ag-20230531_192904/models/LightGBM_BAG_L2/T1/&#39;,
  &#39;LightGBM_BAG_L2/T2&#39;: &#39;/kaggle/working/AutogluonModels/ag-20230531_192904/models/LightGBM_BAG_L2/T2/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230531_192904/models/WeightedEnsemble_L3/&#39;},
 &#39;model_fit_times&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: 54.195430278778076,
  &#39;LightGBM_BAG_L1/T2&#39;: 46.92577528953552,
  &#39;LightGBM_BAG_L1/T3&#39;: 44.92020511627197,
  &#39;WeightedEnsemble_L2&#39;: 0.5340385437011719,
  &#39;LightGBM_BAG_L2/T1&#39;: 42.61614918708801,
  &#39;LightGBM_BAG_L2/T2&#39;: 46.67774772644043,
  &#39;WeightedEnsemble_L3&#39;: 0.4171924591064453},
 &#39;model_pred_times&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: 0.0001933574676513672,
  &#39;LightGBM_BAG_L1/T2&#39;: 0.00012612342834472656,
  &#39;LightGBM_BAG_L1/T3&#39;: 0.00012993812561035156,
  &#39;WeightedEnsemble_L2&#39;: 0.0007405281066894531,
  &#39;LightGBM_BAG_L2/T1&#39;: 0.00011467933654785156,
  &#39;LightGBM_BAG_L2/T2&#39;: 0.00014352798461914062,
  &#39;WeightedEnsemble_L3&#39;: 0.0010159015655517578},
 &#39;num_bag_folds&#39;: 8,
 &#39;max_stack_level&#39;: 3,
 &#39;model_hyperparams&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T3&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                  model  score_val  pred_time_val    fit_time  \
 0   LightGBM_BAG_L2/T2 -39.175397       0.000593  192.719158   
 1  WeightedEnsemble_L3 -39.175397       0.001609  193.136351   
 2   LightGBM_BAG_L1/T2 -39.960581       0.000126   46.925775   
 3  WeightedEnsemble_L2 -39.960581       0.000867   47.459814   
 4   LightGBM_BAG_L2/T1 -41.130442       0.000564  188.657560   
 5   LightGBM_BAG_L1/T3 -49.237221       0.000130   44.920205   
 6   LightGBM_BAG_L1/T1 -53.785746       0.000193   54.195430   
 
    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                0.000144          46.677748            2       True   
 1                0.001016           0.417192            3       True   
 2                0.000126          46.925775            1       True   
 3                0.000741           0.534039            2       True   
 4                0.000115          42.616149            2       True   
 5                0.000130          44.920205            1       True   
 6                0.000193          54.195430            1       True   
 
    fit_order  
 0          6  
 1          7  
 2          2  
 3          4  
 4          5  
 5          3  
 6          1  }</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="39"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:37:49.761559Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:37:49.761227Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T19:37:52.508821Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T19:37:52.507466Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:37:49.761532Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb70"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>prediction_new_hpo <span class="op">=</span> predictor_new_hpo.predict(test)</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>prediction_new_hpo.head()</span></code></pre></div>
<div class="output stream stderr">
<pre><code>2023-05-31 19:37:50,580	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 19:37:50,698	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
</code></pre>
</div>
<div class="output execute_result" data-execution_count="39">
<pre><code>0    15.402902
1    11.066591
2    11.066591
3    11.066591
4    11.066591
Name: count, dtype: float32</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="51"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T19:59:23.789310Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T19:59:23.788589Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T20:10:37.112581Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T20:10:37.109744Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T19:59:23.789274Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb73"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>num_trials <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>search_strategy <span class="op">=</span> <span class="st">&#39;auto&#39;</span></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>hyperparameters <span class="op">=</span> {</span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;NN&#39;</span>: {<span class="st">&#39;num_epochs&#39;</span>:<span class="dv">10</span>, <span class="st">&#39;batch_size&#39;</span>: <span class="dv">32</span>}, </span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;GBM&#39;</span>: {<span class="st">&#39;num_boost_round&#39;</span>: <span class="dv">50</span>}</span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a>hyperparameter_tune_kwargs <span class="op">=</span> { </span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;num_trials&#39;</span>: num_trials,</span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;scheduler&#39;</span> : <span class="st">&#39;local&#39;</span>,</span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;searcher&#39;</span>: search_strategy,</span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb73-12"><a href="#cb73-12" aria-hidden="true" tabindex="-1"></a>predictor_new_hpo <span class="op">=</span> TabularPredictor(</span>
<span id="cb73-13"><a href="#cb73-13" aria-hidden="true" tabindex="-1"></a>      label<span class="op">=</span><span class="st">&quot;count&quot;</span>, </span>
<span id="cb73-14"><a href="#cb73-14" aria-hidden="true" tabindex="-1"></a>      problem_type<span class="op">=</span><span class="st">&quot;regression&quot;</span>, </span>
<span id="cb73-15"><a href="#cb73-15" aria-hidden="true" tabindex="-1"></a>      eval_metric<span class="op">=</span><span class="st">&quot;root_mean_squared_error&quot;</span>, </span>
<span id="cb73-16"><a href="#cb73-16" aria-hidden="true" tabindex="-1"></a>      learner_kwargs<span class="op">=</span>{<span class="st">&quot;ignored_columns&quot;</span>: [<span class="st">&quot;casual&quot;</span>, <span class="st">&quot;registered&quot;</span>]}</span>
<span id="cb73-17"><a href="#cb73-17" aria-hidden="true" tabindex="-1"></a>  ).fit(</span>
<span id="cb73-18"><a href="#cb73-18" aria-hidden="true" tabindex="-1"></a>      train_data<span class="op">=</span>train, time_limit<span class="op">=</span><span class="dv">1000</span>, presets<span class="op">=</span><span class="st">&quot;best_quality&quot;</span>, hyperparameters<span class="op">=</span>hyperparameters, hyperparameter_tune_kwargs<span class="op">=</span>hyperparameter_tune_kwargs</span>
<span id="cb73-19"><a href="#cb73-19" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230531_195923/&quot;
Presets specified: [&#39;best_quality&#39;]
Warning: hyperparameter tuning is currently experimental and may cause the process to hang.
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 1000s
AutoGluon will save models to &quot;AutogluonModels/ag-20230531_195923/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.10
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat May 20 10:48:19 UTC 2023
Train Data Rows:    10886
Train Data Columns: 13
Label Column: count
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Dropping user-specified ignored columns: [&#39;casual&#39;, &#39;registered&#39;]
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    31289.75 MB
	Train Data (Original)  Memory Usage: 0.98 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 3 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting CategoryFeatureGenerator...
			Fitting CategoryMemoryMinimizeFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;category&#39;, []) : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;datetime&#39;, []) : 1 | [&#39;datetime&#39;]
		(&#39;float&#39;, [])    : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])      : 7 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;humidity&#39;, &#39;year&#39;, &#39;month&#39;, ...]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.1s = Fit runtime
	13 features in original data used to generate 17 features in processed data.
	Train Data (Processed) Memory Usage: 1.1 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.16s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;root_mean_squared_error&#39;
	This metric&#39;s sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 2 stack levels (L1 to L2) ...
	WARNING: &quot;NN&quot; model has been deprecated in v0.4.0 and renamed to &quot;NN_MXNET&quot;. Starting in v0.6.0, specifying &quot;NN&quot; or &quot;NN_MXNET&quot; will raise an exception. Consider instead specifying &quot;NN_TORCH&quot;.
Fitting 2 L1 models ...
Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 299.88s of the 999.83s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb75"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;8f4c5a969a6949db979e80c940d4a303&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
Fitted model: LightGBM_BAG_L1/T1 ...
	-53.7857	 = Validation score   (-root_mean_squared_error)
	41.94s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L1/T2 ...
	-39.9606	 = Validation score   (-root_mean_squared_error)
	46.0s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L1/T3 ...
	-49.2372	 = Validation score   (-root_mean_squared_error)
	46.14s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L1/T4 ...
	-142.8004	 = Validation score   (-root_mean_squared_error)
	44.75s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L1/T5 ...
	-38.9034	 = Validation score   (-root_mean_squared_error)
	43.69s	 = Training   runtime
	0.0s	 = Validation runtime
Hyperparameter tuning model: NeuralNetMXNet_BAG_L1 ... Tuning model for up to 299.88s of the 777.18s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb77"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;635ce101e6674b47941b0d8c5524265c&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=8254, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=8254, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-31 20:03:29,207	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=8255, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-31 20:03:29,224	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=8256, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 20:03:31,481	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=8394, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=8394, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 20:03:53,402	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 20:03:53,629	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 20:03:54,320	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=8540, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=8540, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 20:04:14,238	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 20:04:14,381	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 20:04:14,492	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=8681, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=8681, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-31 20:04:32,430	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=8684, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 20:04:34,894	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 20:04:34,985	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=8823, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=8823, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
No model was trained during hyperparameter tuning NeuralNetMXNet_BAG_L1... Skipping this model.
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 669.91s of remaining time.
	-38.6804	 = Validation score   (-root_mean_squared_error)
	1.12s	 = Training   runtime
	0.01s	 = Validation runtime
	WARNING: &quot;NN&quot; model has been deprecated in v0.4.0 and renamed to &quot;NN_MXNET&quot;. Starting in v0.6.0, specifying &quot;NN&quot; or &quot;NN_MXNET&quot; will raise an exception. Consider instead specifying &quot;NN_TORCH&quot;.
Fitting 2 L2 models ...
Hyperparameter tuning model: LightGBM_BAG_L2 ... Tuning model for up to 300.94s of the 668.73s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb79"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;4f878662e01e42bbaab5ba6ba5d9e7ab&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 20:04:56,396	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 20:04:56,425	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 20:04:56,448	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
Fitted model: LightGBM_BAG_L2/T1 ...
	-39.7702	 = Validation score   (-root_mean_squared_error)
	44.72s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L2/T2 ...
	-37.4224	 = Validation score   (-root_mean_squared_error)
	45.75s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L2/T3 ...
	-39.58	 = Validation score   (-root_mean_squared_error)
	45.81s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L2/T4 ...
	-135.4068	 = Validation score   (-root_mean_squared_error)
	46.48s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L2/T5 ...
	-36.7606	 = Validation score   (-root_mean_squared_error)
	46.86s	 = Training   runtime
	0.0s	 = Validation runtime
Hyperparameter tuning model: NeuralNetMXNet_BAG_L2 ... Tuning model for up to 300.94s of the 438.85s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb81"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;2993786fd5cb47f6bd5beef112f98f98&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=10321, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=10321, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-31 20:09:08,741	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=10322, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 20:09:11,363	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 20:09:11,539	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=10459, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=10459, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 20:09:33,740	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 20:09:33,861	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 20:09:33,973	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=10606, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=10606, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 20:09:54,822	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 20:09:55,274	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 20:09:55,283	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=10743, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=10743, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-31 20:10:16,916	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 20:10:17,027	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 20:10:17,227	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=10883, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=10883, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
No model was trained during hyperparameter tuning NeuralNetMXNet_BAG_L2... Skipping this model.
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 327.48s of remaining time.
2023-05-31 20:10:36,350	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=10885, ip=172.19.2.2)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/opt/conda/lib/python3.10/site-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/opt/conda/lib/python3.10/site-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	-36.7166	 = Validation score   (-root_mean_squared_error)
	0.73s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 673.28s ... Best model: &quot;WeightedEnsemble_L3&quot;
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230531_195923/&quot;)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="52"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T20:10:37.118697Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T20:10:37.118398Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T20:10:37.208435Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T20:10:37.207372Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T20:10:37.118669Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb83"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>predictor_new_hpo.fit_summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                  model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0   WeightedEnsemble_L3  -36.716580       0.001801  315.857465                0.000831           0.727736            3       True         12
1    LightGBM_BAG_L2/T5  -36.760622       0.000823  269.376936                0.000122          46.859658            2       True         11
2    LightGBM_BAG_L2/T2  -37.422411       0.000849  268.270072                0.000147          45.752794            2       True          8
3   WeightedEnsemble_L2  -38.680393       0.010595   90.813594                0.010363           1.122457            2       True          6
4    LightGBM_BAG_L1/T5  -38.903358       0.000110   43.689170                0.000110          43.689170            1       True          5
5    LightGBM_BAG_L2/T3  -39.579997       0.000881  268.325429                0.000180          45.808151            2       True          9
6    LightGBM_BAG_L2/T1  -39.770196       0.000821  267.241772                0.000120          44.724494            2       True          7
7    LightGBM_BAG_L1/T2  -39.960581       0.000122   46.001968                0.000122          46.001968            1       True          2
8    LightGBM_BAG_L1/T3  -49.237221       0.000116   46.138285                0.000116          46.138285            1       True          3
9    LightGBM_BAG_L1/T1  -53.785746       0.000203   41.935176                0.000203          41.935176            1       True          1
10   LightGBM_BAG_L2/T4 -135.406804       0.000811  268.999704                0.000110          46.482426            2       True         10
11   LightGBM_BAG_L1/T4 -142.800368       0.000151   44.752680                0.000151          44.752680            1       True          4
Number of models trained: 12
Types of models trained:
{&#39;WeightedEnsembleModel&#39;, &#39;StackerEnsembleModel_LGB&#39;}
Bagging used: True  (with 8 folds)
Multi-layer stack-ensembling used: True  (with 3 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 3 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;year&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/opt/conda/lib/python3.10/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="52">
<pre><code>{&#39;model_types&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T3&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T4&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T5&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBM_BAG_L2/T1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2/T2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2/T3&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2/T4&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2/T5&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: -53.785745858186026,
  &#39;LightGBM_BAG_L1/T2&#39;: -39.96058105317652,
  &#39;LightGBM_BAG_L1/T3&#39;: -49.23722071330252,
  &#39;LightGBM_BAG_L1/T4&#39;: -142.80036825655364,
  &#39;LightGBM_BAG_L1/T5&#39;: -38.903358016442425,
  &#39;WeightedEnsemble_L2&#39;: -38.68039345164393,
  &#39;LightGBM_BAG_L2/T1&#39;: -39.77019591165699,
  &#39;LightGBM_BAG_L2/T2&#39;: -37.422410865151164,
  &#39;LightGBM_BAG_L2/T3&#39;: -39.57999746405541,
  &#39;LightGBM_BAG_L2/T4&#39;: -135.40680404582332,
  &#39;LightGBM_BAG_L2/T5&#39;: -36.76062216001647,
  &#39;WeightedEnsemble_L3&#39;: -36.71658009288973},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L3&#39;,
 &#39;model_paths&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: &#39;/kaggle/working/AutogluonModels/ag-20230531_195923/models/LightGBM_BAG_L1/T1/&#39;,
  &#39;LightGBM_BAG_L1/T2&#39;: &#39;/kaggle/working/AutogluonModels/ag-20230531_195923/models/LightGBM_BAG_L1/T2/&#39;,
  &#39;LightGBM_BAG_L1/T3&#39;: &#39;/kaggle/working/AutogluonModels/ag-20230531_195923/models/LightGBM_BAG_L1/T3/&#39;,
  &#39;LightGBM_BAG_L1/T4&#39;: &#39;/kaggle/working/AutogluonModels/ag-20230531_195923/models/LightGBM_BAG_L1/T4/&#39;,
  &#39;LightGBM_BAG_L1/T5&#39;: &#39;/kaggle/working/AutogluonModels/ag-20230531_195923/models/LightGBM_BAG_L1/T5/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230531_195923/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBM_BAG_L2/T1&#39;: &#39;/kaggle/working/AutogluonModels/ag-20230531_195923/models/LightGBM_BAG_L2/T1/&#39;,
  &#39;LightGBM_BAG_L2/T2&#39;: &#39;/kaggle/working/AutogluonModels/ag-20230531_195923/models/LightGBM_BAG_L2/T2/&#39;,
  &#39;LightGBM_BAG_L2/T3&#39;: &#39;/kaggle/working/AutogluonModels/ag-20230531_195923/models/LightGBM_BAG_L2/T3/&#39;,
  &#39;LightGBM_BAG_L2/T4&#39;: &#39;/kaggle/working/AutogluonModels/ag-20230531_195923/models/LightGBM_BAG_L2/T4/&#39;,
  &#39;LightGBM_BAG_L2/T5&#39;: &#39;/kaggle/working/AutogluonModels/ag-20230531_195923/models/LightGBM_BAG_L2/T5/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230531_195923/models/WeightedEnsemble_L3/&#39;},
 &#39;model_fit_times&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: 41.93517589569092,
  &#39;LightGBM_BAG_L1/T2&#39;: 46.001967668533325,
  &#39;LightGBM_BAG_L1/T3&#39;: 46.1382851600647,
  &#39;LightGBM_BAG_L1/T4&#39;: 44.7526798248291,
  &#39;LightGBM_BAG_L1/T5&#39;: 43.68916964530945,
  &#39;WeightedEnsemble_L2&#39;: 1.1224565505981445,
  &#39;LightGBM_BAG_L2/T1&#39;: 44.724493741989136,
  &#39;LightGBM_BAG_L2/T2&#39;: 45.75279355049133,
  &#39;LightGBM_BAG_L2/T3&#39;: 45.80815076828003,
  &#39;LightGBM_BAG_L2/T4&#39;: 46.482425689697266,
  &#39;LightGBM_BAG_L2/T5&#39;: 46.859657526016235,
  &#39;WeightedEnsemble_L3&#39;: 0.7277355194091797},
 &#39;model_pred_times&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: 0.00020313262939453125,
  &#39;LightGBM_BAG_L1/T2&#39;: 0.00012159347534179688,
  &#39;LightGBM_BAG_L1/T3&#39;: 0.00011563301086425781,
  &#39;LightGBM_BAG_L1/T4&#39;: 0.0001513957977294922,
  &#39;LightGBM_BAG_L1/T5&#39;: 0.00010967254638671875,
  &#39;WeightedEnsemble_L2&#39;: 0.010363340377807617,
  &#39;LightGBM_BAG_L2/T1&#39;: 0.00011968612670898438,
  &#39;LightGBM_BAG_L2/T2&#39;: 0.00014734268188476562,
  &#39;LightGBM_BAG_L2/T3&#39;: 0.00017952919006347656,
  &#39;LightGBM_BAG_L2/T4&#39;: 0.00010991096496582031,
  &#39;LightGBM_BAG_L2/T5&#39;: 0.00012183189392089844,
  &#39;WeightedEnsemble_L3&#39;: 0.0008306503295898438},
 &#39;num_bag_folds&#39;: 8,
 &#39;max_stack_level&#39;: 3,
 &#39;model_hyperparams&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T3&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T4&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T5&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T3&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T4&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T5&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                   model   score_val  pred_time_val    fit_time  \
 0   WeightedEnsemble_L3  -36.716580       0.001801  315.857465   
 1    LightGBM_BAG_L2/T5  -36.760622       0.000823  269.376936   
 2    LightGBM_BAG_L2/T2  -37.422411       0.000849  268.270072   
 3   WeightedEnsemble_L2  -38.680393       0.010595   90.813594   
 4    LightGBM_BAG_L1/T5  -38.903358       0.000110   43.689170   
 5    LightGBM_BAG_L2/T3  -39.579997       0.000881  268.325429   
 6    LightGBM_BAG_L2/T1  -39.770196       0.000821  267.241772   
 7    LightGBM_BAG_L1/T2  -39.960581       0.000122   46.001968   
 8    LightGBM_BAG_L1/T3  -49.237221       0.000116   46.138285   
 9    LightGBM_BAG_L1/T1  -53.785746       0.000203   41.935176   
 10   LightGBM_BAG_L2/T4 -135.406804       0.000811  268.999704   
 11   LightGBM_BAG_L1/T4 -142.800368       0.000151   44.752680   
 
     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                 0.000831           0.727736            3       True   
 1                 0.000122          46.859658            2       True   
 2                 0.000147          45.752794            2       True   
 3                 0.010363           1.122457            2       True   
 4                 0.000110          43.689170            1       True   
 5                 0.000180          45.808151            2       True   
 6                 0.000120          44.724494            2       True   
 7                 0.000122          46.001968            1       True   
 8                 0.000116          46.138285            1       True   
 9                 0.000203          41.935176            1       True   
 10                0.000110          46.482426            2       True   
 11                0.000151          44.752680            1       True   
 
     fit_order  
 0          12  
 1          11  
 2           8  
 3           6  
 4           5  
 5           9  
 6           7  
 7           2  
 8           3  
 9           1  
 10         10  
 11          4  }</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="54"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T20:13:53.960339Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T20:13:53.959863Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T20:13:56.197201Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T20:13:56.196450Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T20:13:53.960296Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb87"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>prediction_new_hpo <span class="op">=</span> predictor_new_hpo.predict(test)</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>prediction_new_hpo.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="54">
<pre><code>0    12.139433
1     8.154926
2     7.435127
3     7.435127
4     7.435127
Name: count, dtype: float32</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="55"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T20:13:57.657058Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T20:13:57.656221Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T20:13:57.711930Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T20:13:57.711108Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T20:13:57.657020Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb89"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remember to set all negative values to zero</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(prediction_new_hpo)):</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> prediction_new_hpo[i] <span class="op">&lt;</span> <span class="dv">0</span>:</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>        prediction_new_hpo[i]<span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="56"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T20:14:00.960755Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T20:14:00.959808Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T20:14:00.998154Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T20:14:00.997232Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T20:14:00.960713Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb90"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>submission_new_hpo <span class="op">=</span> pd.read_csv(<span class="st">&#39;/kaggle/working/submission.csv&#39;</span>)</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>submission_new_hpo[<span class="st">&quot;count&quot;</span>] <span class="op">=</span> prediction_new_hpo</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>submission_new_hpo.to_csv(<span class="st">&quot;submission_new_hpo.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="53"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T20:10:37.210247Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T20:10:37.209859Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T20:10:41.026094Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T20:10:41.025076Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T20:10:37.210218Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb91"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>prediction_new_hpo <span class="op">=</span> predictor_new_hpo.predict(test)</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>prediction_new_hpo.head()</span></code></pre></div>
<div class="output stream stderr">
<pre><code>2023-05-31 20:10:37,626	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
2023-05-31 20:10:37,981	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
</code></pre>
</div>
<div class="output execute_result" data-execution_count="53">
<pre><code>0    12.139433
1     8.154926
2     7.435127
3     7.435127
4     7.435127
Name: count, dtype: float32</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="57"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T20:14:10.433127Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T20:14:10.432279Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T20:14:16.758530Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T20:14:16.756968Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T20:14:10.433089Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb94"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submit <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">-</span>f submission_new_hpo.csv <span class="op">-</span>m <span class="st">&quot;new features with hyperparameters&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>100%|████████████████████████████████████████| 188k/188k [00:02&lt;00:00, 65.6kB/s]
Successfully submitted to Bike Sharing Demand</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="58"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T20:14:16.762007Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T20:14:16.761479Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T20:14:19.736022Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T20:14:19.734532Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T20:14:16.761951Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb96"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submissions <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">|</span> tail <span class="op">-</span>n <span class="op">+</span><span class="dv">1</span> <span class="op">|</span> head <span class="op">-</span>n <span class="dv">6</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>fileName                     date                 description                        status    publicScore  privateScore  
---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  
submission_new_hpo.csv       2023-05-31 20:14:15  new features with hyperparameters  pending                              
submission_new_hpo.csv       2023-05-31 19:41:40  new features with hyperparameters  complete  0.57308      0.57308       
submission_new_hpo.csv       2023-05-31 19:37:58  new features with hyperparameters  complete  0.57308      0.57308       
submission_new_features.csv  2023-05-31 19:22:55  new features 3_2                   complete  0.64166      0.64166       
</code></pre>
</div>
</div>
<section id="new-score-of-517" class="cell markdown">
<h4>New Score of <code>.517</code></h4>
</section>
<section id="step-7-write-a-report" class="cell markdown">
<h2>Step 7: Write a Report</h2>
<h3 id="refer-to-the-markdown-file-for-the-full-report">Refer to the
markdown file for the full report</h3>
<h3 id="creating-plots-and-table-for-report">Creating plots and table
for report</h3>
</section>
<div class="cell code" data-execution_count="60"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T20:23:21.898586Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T20:23:21.898191Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T20:23:21.911007Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T20:23:21.910271Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T20:23:21.898556Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb98"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>predictor.leaderboard(silent<span class="op">=</span><span class="va">True</span>)[<span class="st">&#39;score_val&#39;</span>][<span class="dv">0</span>]</span></code></pre></div>
<div class="output execute_result" data-execution_count="60">
<pre><code>0.9150858441075591</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="61"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T20:23:28.870207Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T20:23:28.869804Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T20:23:28.886334Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T20:23:28.884765Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T20:23:28.870175Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb100"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>predictor_new_features.leaderboard(silent<span class="op">=</span><span class="va">True</span>)[<span class="st">&#39;score_val&#39;</span>][<span class="dv">0</span>]</span></code></pre></div>
<div class="output execute_result" data-execution_count="61">
<pre><code>0.9718099411474068</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="62"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T20:23:34.784683Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T20:23:34.784271Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T20:23:34.798442Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T20:23:34.797122Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T20:23:34.784655Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb102"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>predictor_new_hpo.leaderboard(silent<span class="op">=</span><span class="va">True</span>)[<span class="st">&#39;score_val&#39;</span>][<span class="dv">0</span>]</span></code></pre></div>
<div class="output execute_result" data-execution_count="62">
<pre><code>-36.71658009288973</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="63"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T20:25:35.651181Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T20:25:35.650394Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T20:25:36.132306Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T20:25:36.131257Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T20:25:35.651145Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb104"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Taking the top model score from each training run and creating a line plot to show improvement</span></span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a><span class="co"># You can create these in the notebook and save them to PNG or use some other tool (e.g. google sheets, excel)</span></span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> pd.DataFrame(</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;model&quot;</span>: [<span class="st">&quot;initial&quot;</span>, <span class="st">&quot;add_features&quot;</span>, <span class="st">&quot;hpo&quot;</span>],</span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;score&quot;</span>: [<span class="fl">0.9150858441075591</span>, <span class="fl">0.9718099411474068</span>, <span class="op">-</span><span class="fl">36.71658009288973</span>]</span>
<span id="cb104-7"><a href="#cb104-7" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb104-8"><a href="#cb104-8" aria-hidden="true" tabindex="-1"></a>).plot(x<span class="op">=</span><span class="st">&quot;model&quot;</span>, y<span class="op">=</span><span class="st">&quot;score&quot;</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>)).get_figure()</span>
<span id="cb104-9"><a href="#cb104-9" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">&#39;model_train_score.png&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_5a3329f1f7c34305ae70eb667a8aba9d/4b550f9f200810781cc08365ccd8bca5df5b2080.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="64"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T20:25:41.799497Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T20:25:41.799079Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T20:25:42.280872Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T20:25:42.279478Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T20:25:41.799465Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb105"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Take the 3 kaggle scores and creating a line plot to show improvement</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> pd.DataFrame(</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;test_eval&quot;</span>: [<span class="st">&quot;initial&quot;</span>, <span class="st">&quot;add_features&quot;</span>, <span class="st">&quot;hpo&quot;</span>],</span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;score&quot;</span>: [<span class="fl">1.8</span>, <span class="fl">0.64</span>, <span class="fl">0.517</span>]</span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a>).plot(x<span class="op">=</span><span class="st">&quot;test_eval&quot;</span>, y<span class="op">=</span><span class="st">&quot;score&quot;</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>)).get_figure()</span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">&#39;model_test_score.png&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_5a3329f1f7c34305ae70eb667a8aba9d/f89ca322c56909ec948e2c497324552c81f18bbf.png" /></p>
</div>
</div>
<section id="hyperparameter-table" class="cell markdown">
<h3>Hyperparameter table</h3>
</section>
<div class="cell code" data-execution_count="65"
data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-31T20:28:52.591334Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-31T20:28:52.590837Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-31T20:28:52.608386Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-31T20:28:52.607003Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-31T20:28:52.591287Z&quot;}"
data-trusted="true">
<div class="sourceCode" id="cb106"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The 3 hyperparameters we tuned with the kaggle score as the result</span></span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({</span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;model&quot;</span>: [<span class="st">&quot;initial&quot;</span>, <span class="st">&quot;add_features&quot;</span>, <span class="st">&quot;hpo&quot;</span>],</span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;hpo1&quot;</span>: [<span class="dv">600</span>, <span class="dv">600</span>, <span class="dv">1000</span>],</span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;hpo2&quot;</span>: [<span class="st">&#39;default&#39;</span>, <span class="st">&#39;default&#39;</span>, <span class="st">&#39;models and learning rate&#39;</span>],</span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;hpo3&quot;</span>: [<span class="st">&#39;default&#39;</span>, <span class="st">&#39;default&#39;</span>, <span class="st">&#39;time increased&#39;</span>],</span>
<span id="cb106-7"><a href="#cb106-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;score&quot;</span>: [<span class="fl">0.9150858441075591</span>, <span class="fl">0.9718099411474068</span>, <span class="op">-</span><span class="fl">36.71658009288973</span></span>
<span id="cb106-8"><a href="#cb106-8" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb106-9"><a href="#cb106-9" aria-hidden="true" tabindex="-1"></a>})</span></code></pre></div>
<div class="output execute_result" data-execution_count="65">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>model</th>
      <th>hpo1</th>
      <th>hpo2</th>
      <th>hpo3</th>
      <th>score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>initial</td>
      <td>600</td>
      <td>default</td>
      <td>default</td>
      <td>0.915086</td>
    </tr>
    <tr>
      <th>1</th>
      <td>add_features</td>
      <td>600</td>
      <td>default</td>
      <td>default</td>
      <td>0.971810</td>
    </tr>
    <tr>
      <th>2</th>
      <td>hpo</td>
      <td>1000</td>
      <td>models and learning rate</td>
      <td>time increased</td>
      <td>-36.716580</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code">
<div class="sourceCode" id="cb107"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
</body>
</html>
